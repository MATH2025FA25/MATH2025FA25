{
  "hash": "83ac8008d1b5fa3156a87b39890c383c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Model comparison\"\nauthor: \"Prof. Eric Friedlander\"\nfooter: \"[ðŸ”— MAT 212 - Winter 2025 -  Schedule](https://mat212wi25.netlify.app/schedule)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: false\n    incremental: false \n    chalkboard: true\nhtml-math-method:\n  method: mathjax\n  url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\nexecute:\n  freeze: auto\n  echo: true\n  cache: false\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib  \n---\n\n\n\n\n\n## Announcements\n\n::: appex\nðŸ“‹ [AE 11 - Model Comparison](/ae/ae-11-comparison.qmd)\n\n- Open up AE 11 and complete Exercises 0-2\n:::\n\n\n## Topics\n\n::: nonincremental\n-   ANOVA for multiple linear regression and sum of squares\n-   Comparing models with $R^2$ vs. $R^2_{ajd}$ \n-   Comparing models with AIC and BIC\n-   Occam's razor and parsimony\n:::\n\n\n## Computational setup\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(yardstick)\nlibrary(ggformula)\nlibrary(supernova)\nlibrary(tidymodels)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(janitor)\nlibrary(kableExtra)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))\n```\n:::\n\n\n\n# Introduction\n\n## Data: Restaurant tips\n\nWhich variables help us predict the amount customers tip at a restaurant?\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 169 Ã— 4\n     Tip Party Meal   Age   \n   <dbl> <dbl> <chr>  <chr> \n 1  2.99     1 Dinner Yadult\n 2  2        1 Dinner Yadult\n 3  5        1 Dinner SenCit\n 4  4        3 Dinner Middle\n 5 10.3      2 Dinner SenCit\n 6  4.85     2 Dinner Middle\n 7  5        4 Dinner Yadult\n 8  4        3 Dinner Middle\n 9  5        2 Dinner Middle\n10  1.58     1 Dinner SenCit\n# â„¹ 159 more rows\n```\n\n\n:::\n:::\n\n\n\n## Variables\n\n**Predictors**:\n\n::: nonincremental\n-   `Party`: Number of people in the party\n-   `Meal`: Time of day (`Lunch`, `Dinner`, `Late Night`)\n-   `Age`: Age category of person paying the bill (`Yadult`, `Middle`, `SenCit`)\n:::\n\n**Outcome**: `Tip`: Amount of tip\n\n## Outcome: `Tip`\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](11-comparison_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n\n## Predictors\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](11-comparison_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n\n## Relevel categorical predictors\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntips <- tips |>\n  mutate(\n    Meal = fct_relevel(Meal, \"Lunch\", \"Dinner\", \"Late Night\"),\n    Age  = fct_relevel(Age, \"Yadult\", \"Middle\", \"SenCit\")\n  )\n```\n:::\n\n\n\n## Predictors, again\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](11-comparison_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=3000}\n:::\n:::\n\n\n\n## Outcome vs. predictors\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](11-comparison_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='center' width=3600}\n:::\n:::\n\n\n\n## Fit and summarize model {.midi}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value|\n|:-----------|--------:|---------:|---------:|-------:|\n|(Intercept) |   -0.170|     0.366|    -0.465|   0.643|\n|Party       |    1.837|     0.124|    14.758|   0.000|\n|AgeMiddle   |    1.009|     0.408|     2.475|   0.014|\n|AgeSenCit   |    1.388|     0.485|     2.862|   0.005|\n\n\n:::\n:::\n\n\n\n. . .\n\n<br>\n\n::: question\nIs this model good?\n:::\n\n## Another model summary\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(tip_fit) |>\n  tidy() |>\n  kable(digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n|term      |  df|   sumsq|  meansq| statistic| p.value|\n|:---------|---:|-------:|-------:|---------:|-------:|\n|Party     |   1| 1188.64| 1188.64|    285.71|    0.00|\n|Age       |   2|   38.03|   19.01|      4.57|    0.01|\n|Residuals | 165|  686.44|    4.16|        NA|      NA|\n\n\n:::\n:::\n\n\n\n# Analysis of variance (ANOVA)\n\n## Analysis of variance (ANOVA)\n\n<br>\n\n![](images/12/model-anova.png){fig-align=\"center\"}\n\n## ANOVA {.smaller}\n\n-   **Main Idea:** Decompose the total variation of the outcome into:\n    -   the variation that can be explained by the each of the variables in the model\n    -   the variation that **can't** be explained by the model (left in the residuals)\n-   $SS_{Total}$: Total sum of squares, variability of outcome, $\\sum_{i = 1}^n (y_i - \\bar{y})^2$\n-   $SS_{Error}$: Residual sum of squares, variability of residuals, $\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2$\n-   $SS_{Model} = SS_{Total} - SS_{Error}$: Variability explained by the model, $\\sum_{i = 1}^n (\\hat{y}_i - \\bar{y})^2$\n\n . . .\n \n Complete Exercise 3.\n\n## ANOVA output in R[^1]\n\n[^1]: [Click here](anova-table.html) for explanation about the way R calculates sum of squares for each variable.\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|term      |  df|      sumsq|      meansq|  statistic|  p.value|\n|:---------|---:|----------:|-----------:|----------:|--------:|\n|Party     |   1| 1188.63588| 1188.635880| 285.711511| 0.000000|\n|Age       |   2|   38.02783|   19.013916|   4.570361| 0.011699|\n|Residuals | 165|  686.44389|    4.160266|         NA|       NA|\n\n\n:::\n:::\n\n\n\n## ANOVA output, with totals\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|term      |  df|   sumsq|meansq  |statistic |p.value |\n|:---------|---:|-------:|:-------|:---------|:-------|\n|Party     |   1| 1188.64|1188.64 |285.71    |0       |\n|Age       |   2|   38.03|19.01   |4.57      |0.01    |\n|Residuals | 165|  686.44|4.16    |          |        |\n|Total     | 168| 1913.11|        |          |        |\n\n\n:::\n:::\n\n\n\n## Sum of squares {.smaller}\n\n::: columns\n::: {.column width=\"50%\"}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> df </th>\n   <th style=\"text-align:right;\"> sumsq </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Party </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 1188.64 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Age </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 38.03 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Residuals </td>\n   <td style=\"text-align:right;\"> 165 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 686.44 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Total </td>\n   <td style=\"text-align:right;\"> 168 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 1913.11 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n-   $SS_{Total}$: Total sum of squares, variability of outcome, $\\sum_{i = 1}^n (y_i - \\bar{y})^2$\n-   $SS_{Error}$: Residual sum of squares, variability of residuals, $\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2$\n-   $SS_{Model} = SS_{Total} - SS_{Error}$: Variability explained by the model, $\\sum_{i = 1}^n (\\hat{y}_i - \\bar{y})^2$\n:::\n:::\n\n\n## Sum of squares: $SS_{Total}$\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> df </th>\n   <th style=\"text-align:right;\"> sumsq </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Party </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1188.64 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Age </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 38.03 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Residuals </td>\n   <td style=\"text-align:right;\"> 165 </td>\n   <td style=\"text-align:right;\"> 686.44 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;background-color: rgba(217, 227, 228, 255) !important;\"> Total </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 168 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 1913.11 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n<br>\n\n<center>\n\n$SS_{Total}$: Total sum of squares, variability of outcome\n\n<br>\n\n$\\sum_{i = 1}^n (y_i - \\bar{y})^2$ = 1913.11\n\n</center>\n\n## Sum of squares: $SS_{Error}$\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> df </th>\n   <th style=\"text-align:right;\"> sumsq </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Party </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 1188.64 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Age </td>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:right;\"> 38.03 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;background-color: rgba(217, 227, 228, 255) !important;\"> Residuals </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 165 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 686.44 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Total </td>\n   <td style=\"text-align:right;\"> 168 </td>\n   <td style=\"text-align:right;\"> 1913.11 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n<br>\n\n<center>\n\n$SS_{Error}$: Residual sum of squares, variability of residuals\n\n<br>\n\n$\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2$ = 686.44\n\n</center>\n\n## Sum of squares: $SS_{Model}$\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> df </th>\n   <th style=\"text-align:right;\"> sumsq </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;background-color: rgba(217, 227, 228, 255) !important;\"> Party </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 1 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 1188.64 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;background-color: rgba(217, 227, 228, 255) !important;\"> Age </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 2 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 38.03 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Residuals </td>\n   <td style=\"text-align:right;\"> 165 </td>\n   <td style=\"text-align:right;\"> 686.44 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Total </td>\n   <td style=\"text-align:right;\"> 168 </td>\n   <td style=\"text-align:right;\"> 1913.11 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n<br>\n\n<center>\n\n$SS_{Model}$: Variability explained by the model\n\n<br>\n\n$\\sum_{i = 1}^n (\\hat{y}_i - \\bar{y})^2 = SS_{Model} = SS_{Total} - SS_{Error} =$ 1226.67\n\n</center>\n\n## F-Test: Testing the whole model at once {.smaller}\n\n**Hypotheses:** \n\n$H_0: \\beta_1 = \\beta_2 = \\cdots = \\beta_k = 0$ vs. $H_A:$ at least one $\\beta_i \\neq 0$ \n\n. . .\n\n**Test statistic:** F-statistics\n\n$$\nF = \\frac{MSModel}{MSE} = \\frac{SSModel/k}{SSE/(n-k-1)} \\\\\n$$\n\n. . .\n\n**p-value:** Probability of observing a test statistic at least as extreme (in the direction of the alternative hypothesis) from the null value as the one observed\n\n$$\n\\text{p-value} = P(F > \\text{test statistic}),\n$$\n\ncalculated from an $F$ distribution with $k$ and $n - k - 1$ degrees of freedom.\n\n## F-test in R\n\n- Use `glance` function from `broom` package\n  - `statistic`: F-statistic\n  - `p.value`: p-value from F-test\n\n. . .\n\nComplete Exercise 4.\n\n# Comparing sets of predictors\n\n## Nested Models {.smaller}\n\n-   We say one model is **nested** inside another model if all of its **TERMS** are present in the other model\n\n. . .\n\n-   Consider three different models:\n    -   **Model 1:** $Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\beta_3X_3 + \\epsilon$\n    -   **Model 2:** $Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\epsilon$\n    -   **Model 3:** $Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\beta_3X_1X_2 + \\epsilon$\n  \n. . .\n\n-   **Model 2** is nested inside both **Model 1** and **Model 3**. \n-   Why isn't **Model 3** nested in **Model 1**?\n-   Smaller model is called the **Reduced Model**\n-   Larger model is called the **Full Model** (be careful, this term depends on context)\n\n. . .\n\n- Complete Exercises 5-7.\n\n## Recall: ANOVA, F-Test {.smaller}\n\n**Hypotheses:** \n\n$H_0: \\beta_1 = \\beta_2 = \\cdots = \\beta_p = 0$ vs. $H_A:$ at least one $\\beta_i \\neq 0$ \n\n**Test statistic:** F-statistic\n\n$$\nF = \\frac{MSModel}{MSE} = \\frac{SSModel/p}{SSE/(n-p-1)} \\\\\n$$\n\n**p-value:** Probability of observing a test statistic at least as extreme (in the direction of the alternative hypothesis) from the null value as the one observed\n\n$$\n\\text{p-value} = P(F > \\text{test statistic}),\n$$\n\ncalculated from an $F$ distribution with $p$ and $n - p - 1$ degrees of freedom.\n\n## Nested F-Test {.smaller}\n\nSuppose $k$ is the number of $\\beta$'s in the nested model and $p$ is the full number of predictors in the larger model. I.e. $\\beta_{k+1},\\ldots, \\beta_{p}$ are the new $\\beta$'s\n\n**Hypotheses:** \n\n$H_0: \\beta_{k+1} = \\beta_{k+2} = \\cdots = \\beta_p = 0$ vs. $H_A:$ at least one $\\beta_i \\neq 0$ for $i>k+1$ \n\n**Test statistic:** F-statistic\n\n$$\nF = \\frac{(SSModel_{full} - SSModel_{reduced})/(p-k)}{SSE_{full}/(n-p-1)} \\\\\n$$\n\n**p-value:** Probability of observing a test statistic at least as extreme (in the direction of the alternative hypothesis) from the null value as the one observed\n\n$$\n\\text{p-value} = P(F > \\text{test statistic}),\n$$\n\ncalculated from an $F$ distribution with $p-k$ (the number of predictors being tested) and $n - p - 1$ degrees of freedom.\n\n. . .\n\nNote: Same as regular F-test if reduced model is just $Y= \\beta_0$.\n\n## Nested F-Test in R {.smaller}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntip_fit_1 <- lm(Tip ~ Party + Age + Meal, data = tips)\ntip_fit_2 <- lm(Tip ~ Party + Age + Meal + Day, data = tips)\n\nanova(tip_fit_1, tip_fit_2) |> # Enter reduced model first\n  tidy() |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|term                           | df.residual|      rss| df|    sumsq| statistic|  p.value|\n|:------------------------------|-----------:|--------:|--:|--------:|---------:|--------:|\n|Tip ~ Party + Age + Meal       |         163| 622.9793| NA|       NA|        NA|       NA|\n|Tip ~ Party + Age + Meal + Day |         158| 607.3815|  5| 15.59778| 0.8114993| 0.543086|\n\n\n:::\n:::\n\n\n\n$$\nF = \\frac{(SSModel_{full} - SSModel_{reduced})/(p-k)}{SSE_{full}/(n-p-1)}\n= \\frac{15.59778/5}{6073815/158}\n= 0.8114993\n$$\n\nLet's interpret this together.\n\n. . .\n\nComplete Exercise 8.\n\n\n# Model comparison\n\n## R-squared, $R^2$\n\n**Recall**: $R^2$ is the proportion of the variation in the response variable explained by the regression model.\n\n. . .\n\n$$\nR^2 = \\frac{SS_{Model}}{SS_{Total}} = 1 - \\frac{SS_{Error}}{SS_{Total}}\n$$\n\nComplete Exercises 9-11.\n\n## R-squared, $R^2$, Overfitting\n\n-   $R^2$ will always increase as we add more variables to the model \n    +   If we add enough variables, we can usually achieve $R^2=100\\%$\n    +   Eventually our model will over-align to the noise in our data and become worse at predicting new data... this is called [overfitting](https://en.wikipedia.org/wiki/Overfitting#/media/File:Pyplot_overfitting.png)   \n-   If we only use $R^2$ to choose a best fit model, we will be prone to choosing the model with the most predictor variables\n\n## Adjusted $R^2$\n\n-   **Adjusted** $R^2$: measure that includes a penalty for unnecessary predictor variables\n-   Similar to $R^2$, it is a measure of the amount of variation in the response that is explained by the regression model\n-   Differs from $R^2$ by using the mean squares (sum of squares/degrees of freedom) rather than sums of squares and therefore adjusting for the number of predictor variables\n\n## $R^2$ and Adjusted $R^2$\n\n$$R^2 = \\frac{SS_{Model}}{SS_{Total}} = 1 - \\frac{SS_{Error}}{SS_{Total}}$$\n\n<br>\n\n. . .\n\n$$R^2_{adj} = 1 - \\frac{SS_{Error}/(n-p-1)}{SS_{Total}/(n-1)}$$\n\nwhere\n\n-   $n$ is the number of observations used to fit the model\n\n-   $p$ is the number of terms (not including the intercept) in the model\n\n## Using $R^2$ and Adjusted $R^2$\n\n-   $R^2_{adj}$ can be used as a quick assessment to compare the fit of multiple models; however, it should not be the only assessment!\n-   Use $R^2$ when describing the relationship between the response and predictor variables\n\nComplete Exercises 12-13.\n\n## Comparing models with $R^2_{adj}$ {.smaller}\n\n::: columns\n::: {.column width=\"50%\"}\n`tip_fit_1`:\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n| r.squared| adj.r.squared|    sigma| statistic| p.value| df|    logLik|      AIC|      BIC| deviance| df.residual| nobs|\n|---------:|-------------:|--------:|---------:|-------:|--:|---------:|--------:|--------:|--------:|-----------:|----:|\n| 0.6743626|     0.6643738| 1.954983|  67.51136|       0|  5| -350.0405| 714.0811| 735.9904| 622.9793|         163|  169|\n\n\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n`tip_fit_2`:\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n| r.squared| adj.r.squared|   sigma| statistic| p.value| df|   logLik|      AIC|      BIC| deviance| df.residual| nobs|\n|---------:|-------------:|-------:|---------:|-------:|--:|--------:|--------:|--------:|--------:|-----------:|----:|\n| 0.6825157|     0.6624218| 1.96066|  33.96625|       0| 10| -347.898| 719.7959| 757.3547| 607.3815|         158|  169|\n\n\n:::\n:::\n\n\n:::\n:::\n\n::: question\n1.  Which model would we choose based on $R^2$?\n2.  Which model would we choose based on Adjusted $R^2$?\n3.  Which statistic should we use to choose the final model - $R^2$ or Adjusted $R^2$? Why?\n:::\n\n## AIC & BIC\n\nEstimators of prediction error and *relative* quality of models:\n\n. . .\n\n**Akaike's Information Criterion (AIC)**: $$AIC = n\\log(SS_\\text{Error}) - n \\log(n) + 2(p+1)$$ <br>\n\n. . .\n\n**Schwarz's Bayesian Information Criterion (BIC)**: $$BIC = n\\log(SS_\\text{Error}) - n\\log(n) + log(n)\\times(p+1)$$\n\n\n## AIC & BIC\n\n$$\n\\begin{aligned} \n& AIC = \\color{blue}{n\\log(SS_\\text{Error})} - n \\log(n) + 2(p+1) \\\\\n& BIC = \\color{blue}{n\\log(SS_\\text{Error})} - n\\log(n) + \\log(n)\\times(p+1) \n\\end{aligned}\n$$\n\n. . .\n\n<br>\n\nFirst Term: Decreases as *p* increases... why?\n\n## AIC & BIC\n\n$$\n\\begin{aligned} \n& AIC = n\\log(SS_\\text{Error}) - \\color{blue}{n \\log(n)} + 2(p+1) \\\\\n& BIC = n\\log(SS_\\text{Error}) - \\color{blue}{n\\log(n)} + \\log(n)\\times(p+1) \n\\end{aligned}\n$$\n\n<br>\n\nSecond Term: Fixed for a given sample size *n*\n\n## AIC & BIC\n\n$$\n\\begin{aligned} & AIC = n\\log(SS_\\text{Error}) - n\\log(n) + \\color{blue}{2(p+1)} \\\\\n& BIC = n\\log(SS_\\text{Error}) - n\\log(n) + \\color{blue}{\\log(n)\\times(p+1)} \n\\end{aligned}\n$$\n\n<br>\n\nThird Term: Increases as *p* increases\n\n## Using AIC & BIC\n\n$$\n\\begin{aligned} & AIC = n\\log(SS_{Error}) - n \\log(n) + \\color{red}{2(p+1)} \\\\\n& BIC = n\\log(SS_{Error}) - n\\log(n) + \\color{red}{\\log(n)\\times(p+1)} \n\\end{aligned}\n$$\n\n-   Choose model with the smaller value of AIC or BIC\n\n-   If $n \\geq 8$, the **penalty** for BIC is larger than that of AIC, so BIC tends to favor *more parsimonious* models (i.e. models with fewer terms)\n\nComplete Exercise 14.\n\n## Comparing models with AIC and BIC\n\n::: columns\n::: {.column width=\"50%\"}\n`tip_fit_1`\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|      AIC|      BIC|\n|--------:|--------:|\n| 714.0811| 735.9904|\n\n\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n`tip_fit_2`\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|      AIC|      BIC|\n|--------:|--------:|\n| 719.7959| 757.3547|\n\n\n:::\n:::\n\n\n:::\n:::\n\n::: question\n1.  Which model would we choose based on AIC?\n\n2.  Which model would we choose based on BIC?\n:::\n\n## Commonalities between criteria\n\n-   $R^2_{adj}$, AIC, and BIC all apply a penalty for more predictors\n-   The penalty for added model complexity attempts to strike a balance between underfitting (too few predictors in the model) and overfitting (too many predictors in the model)\n-   Goal: **Parsimony**\n\n## Parsimony and Occam's razor {.small}\n\n-   The principle of **parsimony** is attributed to William of Occam (early 14th-century English nominalist philosopher), who insisted that, given a set of equally good explanations for a given phenomenon, *the correct explanation is the simplest explanation*[^2]\n\n-   Called **Occam's razor** because he \"shaved\" his explanations down to the bare minimum\n\n-   Parsimony in modeling:\n\n    ::: nonincremental\n    -   models should have as few parameters as possible\n    -   linear models should be preferred to non-linear models\n    -   experiments relying on few assumptions should be preferred to those relying on many\n    -   models should be pared down until they are *minimal adequate* (i.e. contain the minimum number of predictors required to meet some critereon)\n    -   simple explanations should be preferred to complex explanations\n    :::\n\n[^2]: Source: The R Book by Michael J. Crawley.\n\n## In pursuit of Occam's razor\n\n-   Occam's razor states that among competing hypotheses that predict equally well, the one with the fewest assumptions should be selected\n\n-   Model selection follows this principle\n\n-   We only want to add another variable to the model if the addition of that variable brings something valuable in terms of predictive power to the model\n\n-   In other words, we prefer the simplest best model, i.e. **parsimonious** model\n\n## Alternate views {.midi}\n\n> Sometimes a simple model will outperform a more complex model . . . Nevertheless, I believe that deliberately limiting the complexity of the model is not fruitful when the problem is evidently complex. Instead, if a simple model is found that outperforms some particular complex model, the appropriate response is to define a different complex model that captures whatever aspect of the problem led to the simple model performing well.\n>\n> <br>\n>\n> Radford Neal - Bayesian Learning for Neural Networks[^3]\n\n[^3]: Suggested blog post: [Occam](https://statmodeling.stat.columbia.edu/2012/06/26/occam-2/) by Andrew Gelman\n\n## Other concerns with our approach {.midi}\n\n-   All criteria we considered for model comparison require making predictions for our data and then uses the prediction error ($SS_{Error}$) somewhere in the formula\n-   But we're making prediction for the data we used to build the model (estimate the coefficients), which can lead to **overfitting**\n\n\n\n# Model Selection\n\n## Model Selection\n\n-   So far: We've come up with a variety of metrics and tests which help us compare different models\n-   How do we choose the models to compare in the first place?\n-   Today: Best subset, forward selection, and backward selection\n\n## AIC, BIC, Mallows' $C_p$ {.smaller}\n\nEstimators of prediction error and *relative* quality of models:\n\n**Akaike's Information Criterion (AIC)**: $$AIC = n\\log(SS_\\text{Error}) - n \\log(n) + 2(p+1)$$ <br>\n\n**Schwarz's Bayesian Information Criterion (BIC)**: $$BIC = n\\log(SS_\\text{Error}) - n\\log(n) + log(n)\\times(p+1)$$\n\n. . .\n\n**Mallows' $C_p$**: $$C_p = \\frac{SSE_{p}}{MSE_{full model}} - n + 2(p+1)$$\n\n## Best Subset Selection\n\n-   Computers are great now!\n-   Frequently feasible to try out EVERY combination of predictors if you total number of possible predictors is not too high.\n\n## Best Subset Selection in R {.smaller}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(olsrr)\n\nfull_model <- lm(Tip ~ ., data = tips)\n\nols_step_best_subset(full_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                         Best Subsets Regression                          \n--------------------------------------------------------------------------\nModel Index    Predictors\n--------------------------------------------------------------------------\n     1         Bill                                                        \n     2         Bday Bill                                                   \n     3         Day Party Bill                                              \n     4         Day Party Bday Bill                                         \n     5         Day Party Age Bday Bill                                     \n     6         Day Payment Party Age Bday Bill                             \n     7         Day Payment Party Age GiftCard Bday Bill                    \n     8         Day Payment Party Age GiftCard Comps Bday Bill              \n     9         Day Payment Party Age GiftCard Comps Alcohol Bday Bill      \n    10         Day Meal Payment Party Age GiftCard Comps Alcohol Bday Bill \n--------------------------------------------------------------------------\n\n                                                    Subsets Regression Summary                                                    \n----------------------------------------------------------------------------------------------------------------------------------\n                       Adj.        Pred                                                                                            \nModel    R-Square    R-Square    R-Square     C(p)        AIC         SBIC        SBC         MSEP       FPE       HSP       APC  \n----------------------------------------------------------------------------------------------------------------------------------\n  1        0.7662      0.7648      0.7582     7.3539    650.0922    170.4124    659.4819    452.6520    2.7101    0.0161    0.2394 \n  2        0.7743      0.7716      0.7585     3.3820    646.1326    166.6253    658.6522    439.6163    2.6474    0.0158    0.2339 \n  3        0.7806      0.7710      0.7526     8.7457    651.3566    164.1101    679.5257    429.9723    2.6689    0.0159    0.2301 \n  4        0.7870      0.7763      0.7548     6.0330    648.3593    161.5085    679.6583    420.0053    2.6224    0.0156    0.2260 \n  5        0.7912      0.7780      0.7512     6.9278    648.9839    160.5385    686.5427    414.2413    2.6181    0.0156    0.2242 \n  6        0.7934      0.7775      0.7433     9.2903    651.1765    161.0873    694.9951    412.3801    2.6384    0.0157    0.2244 \n  7        0.7940      0.7767      0.7374    10.8854    652.7266    162.9029    699.6751    413.8544    2.6634    0.0159    0.2265 \n  8        0.7945      0.7758      0.7346    12.5119    654.3104    164.7602    704.3888    415.4330    2.6893    0.0161    0.2287 \n  9        0.7950      0.7749      0.7315    14.1249    655.8782    166.6146    709.0865    416.9945    2.7151    0.0162    0.2308 \n 10        0.7952      0.7721      0.7225    18.0000    659.7385    168.7314    719.2066    419.3037    2.7641    0.0165    0.2334 \n----------------------------------------------------------------------------------------------------------------------------------\nAIC: Akaike Information Criteria \n SBIC: Sawa's Bayesian Information Criteria \n SBC: Schwarz Bayesian Criteria \n MSEP: Estimated error of prediction, assuming multivariate normality \n FPE: Final Prediction Error \n HSP: Hocking's Sp \n APC: Amemiya Prediction Criteria \n```\n\n\n:::\n:::\n\n\n\nShows you \"best\" model for every model size.\n\n## Backward Elimination {.smaller}\n\nDifferent model selection technique:\n\n1. Start by fitting the full model (the model that includes all terms under consideration).\n2. Identify the term with the largest p-value.\n    a. If p-value is large (say, greater than 5%), eliminate that term to produce a smaller model. Fit that model and return to the start of Step 2.\n    b. If p-value is small (less than 5%), stop since all of the predictors in the model are \"significant.\"\n\nNote: this can be altered to work with other criterea (e.g. AIC) instead of p-values. This is actually what `regsubsets` does.\n\n\n## Forward Selection {.smaller}\n\n1. Start with a model with no predictors and find the best single predictor (the largest correlation with the response gives the biggest initial).\n2. Add the new predictor to the model, run the regression, and find its individual p-value:\n    a. If p-value is small (say, less than 5%), add predictor which would produce the most benefit (biggest increase in $R^2$) when added to the existing model.\n    b. If the p-value is large (over 5%), stop and discard this predictor. At this point, no (unused) predictor should be significant when added to the model and we are done.\n\n## Stepwise Selection {.smaller}\n\nForward, stepwise selection\n\n1. Start with a model with no predictors and find the best single predictor (the largest correlation with the response gives the biggest initial).\n2. Add the new predictor to the model, run the regression, and find its individual p-value:\n    a. If p-value is small (say, less than 5%), **run backward elimination**, then add predictor which would produce the most benefit (biggest increase in $R^2$) when added to the existing model.\n    b. If the p-value is large (over 5%), stop and discard this predictor. At this point, no (unused) predictor should be significant when added to the model and we are done.\n    \n- Why? Sometimes variables that were significant early on, can become insignificant after other new variables are added to the model.\n\nBackward, stepwise selection is the same, except you perform forward selection every time you delete a term from the model.\n\n## CAUTION {.smaller}\n\n-   These automated methods have fallen out of favor in recent years, but you can still use them and should know what they are.\n-   Automated methods ARE NOT a replacement for subject matter expertise\n-   Think of the models that come out of these procedures as *suggestions*\n-   The order in which variables are added to a model can *help* us understand which variables are more important and which are redundant.\n\nComplete Exercise 15.\n\n## Recap\n\n-   ANOVA for multiple linear regression and sum of squares\n-   $R^2$ for multiple linear regression\n-   Comparing models with\n    -   $R^2$ vs.Â $R^2_{Adj}$\n    -   AIC and BIC\n-   Occam's razor and parsimony\n-   Choosing models using:\n    -   Exhaustive search\n    -   Forward/Backward/Stepwise selection\n",
    "supporting": [
      "11-comparison_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}