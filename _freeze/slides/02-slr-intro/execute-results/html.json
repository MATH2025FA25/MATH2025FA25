{
  "hash": "022c39228905e8b0a7f0c71a1c492c02",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Simple Linear Regression\"\nauthor: \"Prof. Eric Friedlander\"\nfooter: \"[ðŸ”— MAT 212 - Winter 2025 -  Schedule](https://mat212wi25.netlify.app/schedule)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: false\n    incremental: false \n    chalkboard: true\nexecute:\n  freeze: auto\n  echo: true\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib  \n---\n\n\n\n\n\n\n\n\n\n\n\n\n## Application exercise\n\n::: appex\nðŸ“‹ [AE 02 - DC Bikeshare](/ae/ae-02-bikeshare.qmd)\n:::\n\nComplete Exercises 0 and 1.\n\n# Introduction to Simple Linear Regression\n\n## Topics\n\n-   Use simple linear regression to describe the relationship between a quantitative predictor and quantitative response variable.\n\n-   Estimate the slope and intercept of the regression line using the least squares method.\n\n-   Interpret the slope and intercept of the regression line.\n\n-   Use R to fit and summarize regression models.\n\n## Computation set up {.smaller}\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)       # for data wrangling\nlibrary(ggformula)       # for plotting\nlibrary(fivethirtyeight) # for the fandango dataset\nlibrary(broom)           # for formatting model output\nlibrary(knitr)           # for formatting tables\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)\n\nbikeshare <- read_csv(\"../data/dcbikeshare.csv\") |> \n  mutate(season = case_when(\n    season == 1 ~ \"winter\",\n    season == 2 ~ \"spring\",\n    season == 3 ~ \"summer\",\n    season == 4 ~ \"fall\"\n  ),\n  season = factor(season))\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Data\n\n## DC Bikeshare\n\nOur data set contains daily rentals from the Capital Bikeshare in Washington, DC in 2011 and 2012. It was obtained from the `dcbikeshare` data set in the `dsbox` R package.\n\nWe will focus on the following variables in the analysis:\n\n-   `count`: total bike rentals\n-   `temp_orig`: Temperature in degrees Celsius\n-   `season`: 1 - winter, 2 - spring, 3 - summer, 4 - fall\n\nClick [here](https://rstudio-education.github.io/dsbox/reference/dcbikeshare.html) for the full list of variables and definitions.\n\nLet's complete Exercises 2-6 together\n\n## Data prep\n\n-   Exercise 2: Recode `season` as a factor with names instead of numbers (livecode)\n-   Remember:\n    +   Think of `|>` as \"and then\"\n    +   `mutate` creates new columns and changes (mutates) existing columns\n    +   R called categorical data \"factors\"\n    \n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbikeshare <- read_csv(\"../data/dcbikeshare.csv\") |> \n  mutate(season = case_when(\n    season == 1 ~ \"winter\",\n    season == 2 ~ \"spring\",\n    season == 3 ~ \"summer\",\n    season == 4 ~ \"fall\"\n  ),\n  season = factor(season))\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Exploratory data analysis (Exercise 3)\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_point(count ~ temp_orig | season, data = bikeshare) |> \n  gf_labs(x = \"Temperature (Celsius)\",\n          y = \"Daily bike rentals\")\n```\n\n::: {.cell-output-display}\n![](02-slr-intro_files/figure-revealjs/unnamed-chunk-3-1.png){width=80%}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Exploratory data analysis (Exercise 3)\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngf_point(count ~ temp_orig | season, data = bikeshare) |> \n  gf_labs(x = \"Temperature (Celsius)\",\n          y = \"Daily bike rentals\")\n```\n\n::: {.cell-output-display}\n![](02-slr-intro_files/figure-revealjs/unnamed-chunk-4-1.png){width=80%}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## More data prep\n\n-   (Exercise 5) Filter your data for the season with the strongest relationship and give the resulting data set a new name\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwinter <- bikeshare |> \n  filter(season == \"winter\")\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Rentals vs Temperature\n\n**Goal**: Fit a line to describe the relationship between the temperature and the number of rentals in winter.\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-slr-intro_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Why fit a line?\n\nWe fit a line to accomplish one or both of the following:\n\n. . .\n\n::: {style=\"color: #799100\"}\n**Prediction**\n:::\n\nHow many rentals are expected when it's 10 degrees out?\\\n\n. . .\n\n::: {style=\"color : #799100\"}\n**Inference**\n:::\n\nIs temperature a useful predictor of the number of rentals? By how much is the number of rentals expected to change for each degree celcius?\n\n## Terminology\n\n::: columns\n::: {.column width=\"30%\"}\n-   **Response, *Y***: variable describing the outcome of interest\n\n-   **Predictor, *X***: variable we use to help understand the variability in the response\n:::\n\n::: {.column width=\"70%\"}\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-slr-intro_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n:::\n:::\n\n## Regression model\n\n**Regression model:** a function that describes the relationship between a quantitive response, $Y$, and the predictor, $X$ (or many predictors).\n\n\n\n\n\n\n\n\n\n\n\n\n```{=tex}\n\\begin{aligned} Y &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon \\end{aligned}\n```\n\n\n\n\n\n\n\n\n\n\n\n\n## Regression model\n\n::: columns\n::: {.column width=\"30%\"}\n\n\n\n\n\n\n\n\n\n\n\n```{=tex}\n\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{purple}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{purple}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon \\end{aligned}\n```\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n::: {.column width=\"70%\"}\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-slr-intro_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n:::\n:::\n\n$\\mu_{Y|X}$ is the mean value of $Y$ given a particular value of $X$.\n\n## Regression model\n\n::: columns\n::: {.column width=\"30%\"}\n$$\n\\begin{aligned} Y &= \\color{purple}{\\textbf{Model}} + \\color{blue}{\\textbf{Error}} \\\\[5pt]\n&= \\color{purple}{\\mathbf{f(X)}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\[5pt]\n&= \\color{purple}{\\boldsymbol{\\mu_{Y|X}}} + \\color{blue}{\\boldsymbol{\\epsilon}} \\\\[5pt]\n \\end{aligned}\n$$\n:::\n\n::: {.column width=\"70%\"}\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-slr-intro_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n:::\n:::\n\n# Simple linear regression (SLR)\n\n## SLR: Statistical model\n\n- **Simple linear regression:** model to describe the relationship between $Y$ and $X$ where:\n  + $Y$ is a quantitative/numerical reponse\n  + $X$ is a *single* quantitative predictor\n  + $$\\Large{Y = \\mathbf{\\beta_0 + \\beta_1 X} + \\epsilon}$$\n\n. . .\n\n-   $\\beta_1$: True slope of the relationship between $X$ and $Y$\n-   $\\beta_0$: True intercept of the relationship between $X$ and $Y$\n-   $\\epsilon$: Error\n\n## SLR: Regression equation\n\n$$\\Large{\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X}$$\n\n-   $\\hat{\\beta}_1$: Estimated slope of the relationship between $X$ and $Y$\n-   $\\hat{\\beta}_0$: Estimated intercept of the relationship between $X$ and $Y$\n-   $\\hat{Y}$: Predicted value of $Y$ for a given $X$\n-   No error term!\n\n## Choosing values for $\\hat{\\beta}_1$ and $\\hat{\\beta}_0$\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-slr-intro_files/figure-revealjs/unnamed-chunk-10-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Residuals\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](02-slr-intro_files/figure-revealjs/unnamed-chunk-11-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n$$\\text{residual} = \\text{observed} - \\text{predicted} = y_i - \\hat{y}_i$$\n\n## Least squares line\n\n-  **Residual** for the $i^{th}$ observation:\n\n$$e_i = \\text{observed} - \\text{predicted}\n= y_i - \\hat{y}_i$$\n\n-   **Sum of squared residuals**:\n\n$$e^2_1 + e^2_2 + \\dots + e^2_n$$\n\n-   **Least squares line** is the one that minimizes the sum of squared residuals\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n# Slope and intercept\n\n## Properties of least squares regression {.smaller}\n\n::: incremental\n-   Passes through center of mass point, the coordinates corresponding to average $X$ and average $Y$: $\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}$\n\n-   Slope has same sign as the correlation coefficient: $\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}$\n\n    + $r$: correlation coefficient\n    + $s_Y, s_X$: sample standard deviations of $X$ and $Y$\n\n-   Sum of the residuals is zero: $\\sum_{i = 1}^n e_i \\approx 0$\n\n    +   Intuition: Residuals are \"balanced\"\n\n-   The residuals and $X$ values are uncorrelated\n:::\n\n## Estimating the slope\n\n$$\\large{\\hat{\\beta}_1 = r \\frac{s_Y}{s_X}}$$\n\n::: columns\n::: {.column width=\"50%\"}\n\n\n\n\n\n\n\n\n\n\n\n```{=tex}\n\\begin{aligned}\ns_X &= 4.2121 \\\\\ns_Y &= 1399.942 \\\\\nr &= 0.6692\n\\end{aligned}\n```\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n\n\n\n\n\n\n\n\n\n```{=tex}\n\\begin{aligned}\n\\hat{\\beta}_1 &= 0.6692 \\times \\frac{1399.942}{4.2121} \\\\\n&= 222.417\\end{aligned}\n```\n\n\n\n\n\n\n\n\n\n\n\n:::\n:::\n\n<br>\n\n::: small\n[Clickhere](https://introregression.netlify.app/98-appendix) for details on deriving the equations for slope and intercept which is easy if you know multivariate calculus.\n:::\n\n## Estimating the intercept\n\n$$\\large{\\hat{\\beta}_0 = \\bar{Y} - \\hat{\\beta}_1\\bar{X}}$$\n\n::: columns\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n\n\n```{=tex}\n\\begin{aligned}\n&\\bar{x} = 12.2076 \\\\\n&\\bar{y} = 2604.133 \\\\\n&\\hat{\\beta}_1 = 222.4167\n\\end{aligned}\n```\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n::: {.column width=\"60%\"}\n\n\n\n\n\n\n\n\n\n\n\n```{=tex}\n\\begin{aligned}\\hat{\\beta}_0 &= 2604.133 - 222.4167 \\times 12.2076 \\\\\n&= -111.0411\n\\end{aligned}\n```\n\n\n\n\n\n\n\n\n\n\n\n:::\n:::\n\n<br>\n\n::: small\n[Click here](https://introregression.netlify.app/98-appendix) for details on deriving the equations for slope and intercept.\n:::\n\n## Interpretation\n\n-  Slope: For each additional unit of $X$ we expect the $Y$ to increase by $\\hat{\\beta}_1$, on average.\n-  Intercept: If $X$ were 0, we predict $Y$ to be $\\hat{\\beta}_0$\n\n\n## Does it make sense to interpret the intercept?\n\nâœ… **The intercept is meaningful in the context of the data if**\n\n-   the predictor can feasibly take values equal to or near zero, or\n\n-   there are values near zero in the observed data.\n\n. . .\n\nðŸ›‘ Otherwise, the intercept may not be meaningful!\n\n## Estimating the regression line in R\n\n-   Let's complete Exercises 7-11\n\n## Fit model & estimate parameters\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|1\"}\nwinter_fit <- lm(count ~ temp_orig, data = winter)\nwinter_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = count ~ temp_orig, data = winter)\n\nCoefficients:\n(Intercept)    temp_orig  \n     -111.0        222.4  \n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Look at the regression output\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|2\"}\nwinter_fit <- lm(count ~ temp_orig, data = winter)\nwinter_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = count ~ temp_orig, data = winter)\n\nCoefficients:\n(Intercept)    temp_orig  \n     -111.0        222.4  \n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n$$\\widehat{\\text{count}} = -111.0 + 222.4 \\times \\text{temp_orig}$$\n\n. . .\n\n::: smallest\n**Note:** The intercept is off by a tiny bit from the hand-calculated intercept, this is just due to rounding in the hand calculation.\n:::\n\n## The regression output\n\nWe'll focus on the first column for now...\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|2\"}\nwinter_fit |> \n  tidy() \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)    -111.     238.     -0.466 6.42e- 1\n2 temp_orig       222.      18.5    12.0   7.28e-25\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Format output with `kable`\n\nUse the `kable` function from the [knitr](https://yihui.org/knitr/) package to produce a table and specify number of significant digits\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|3\"}\nwinter_fit |> \n  tidy() |>\n  kable(digits = 4)\n```\n\n::: {.cell-output-display}\n\n\n|term        |  estimate| std.error| statistic| p.value|\n|:-----------|---------:|---------:|---------:|-------:|\n|(Intercept) | -111.0380|  238.3124|   -0.4659|  0.6418|\n|temp_orig   |  222.4155|   18.4594|   12.0489|  0.0000|\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Visualize Model\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwinter |> \n  gf_point(count ~ temp_orig) |> \n  gf_lm()\n```\n\n::: {.cell-output-display}\n![](02-slr-intro_files/figure-revealjs/unnamed-chunk-17-1.png){width=80%}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n# Prediction\n\n## Our Model\n\n\n\n\n\n\n\n\n\n\n\n\n```{=tex}\n\\begin{aligned}\n\\widehat{Y} &=  -111.0 + 222.4 \\times X\\\\\n\n\\widehat{\\text{count}} &=  -111.0 + 222.4 \\times \\text{temp_orig}\n\\end{aligned}\n```\n\n\n\n\n\n\n\n\n\n\n\n\n## Making a prediction\n\nSuppose that it's 15 degrees celcius outside. According to this model, how many bike rentals should we expect if it's winter?\n\n\n\n\n\n\n\n\n\n\n\n\n```{=tex}\n\\begin{aligned}\n\\widehat{\\text{count}} &= -111.0 + 222.4 \\times \\text{temp_orig} \\\\\n&= -111.0 + 222.4 \\times 15 \\\\\n&= 3225\n\\end{aligned}\n```\n\n\n\n\n\n\n\n\n\n\n\n\n## Prediction in R\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|2|5\"}\n# create a data frame for a new temperature\nnew_day <- tibble(temp_orig = 15)\n\n# predict the outcome for a new day\npredict(winter_fit, new_day)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       1 \n3225.195 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Recap\n\n::: {.incremental style=\"font-size: 0.85em\"}\n-   Used simple linear regression to describe the relationship between a quantitative predictor and quantitative response variable.\n\n-   Used the least squares method to estimate the slope and intercept.\n\n-   Interpreted the slope and intercept.\n\n    -   **Slope**: For every one unit increase in $x$, we expect y to change by $\\hat{\\beta}_1$ units, on average.\n    -   **Intercept**: If $x$ is 0, then we expect $y$ to be $\\hat{\\beta}_0$ units\n\n-   Predicted the response given a value of the predictor variable.\n\n-   Used `lm` and the `broom` package to fit and summarize regression models in R.\n:::\n\n",
    "supporting": [
      "02-slr-intro_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}