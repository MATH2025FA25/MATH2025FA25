{
  "hash": "b796e6b7a53723a1fbc42ace7e70fb20",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"SLR: Simulation-based inference\"\nauthor: \"Prof. Eric Friedlander\"\nfooter: \"[ðŸ”— MAT 212 - Winter 2025 -  Schedule](https://mat212wi25.netlify.app/schedule)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: false\n    incremental: false \n    chalkboard: true\nexecute:\n  freeze: auto\n  echo: true\n  cache: false\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib  \n---\n\n\n\n\n\n\n## Application exercise\n\n::: appex\nðŸ“‹ [AE 03 - Simulation Based Inference](/ae/ae-03-sbi.qmd)\n:::\n\nComplete Exercises 0-2.\n\n# Simulation-Based Inference\n\n-   Bootstrapped confidence intervals\n-   Randomization test for slope\n\n## [Data: San Antonio Income & Organic Food Access]{.r-fit-text}\n\n::: columns\n::: {.column width=\"60%\"}\n-   Average household income (per zip code) and number of organic vegetable offerings in San Antonio, TX\n-   Data from HEB website, compiles by high school student Linda Saucedo, Fall 2019\n-   Source: [**Skew The Script**](https://skewthescript.org/3-1)\n:::\n\n::: {.column width=\"40%\"}\n![](images/03/HEB-Logo.jpg)\n:::\n:::\n\n**Goal**: Use the average household income to understand variation in access to organic foods.\n\n\n## Computational setup\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(ggformula)  # for modeling\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for neatly formatted tables\nlibrary(kableExtra)  # also for neatly formatted tablesf\n\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 16))\n```\n:::\n\n\n\n\n# Bootstrapped confidence intervals: Topics\n\n-   Find range of plausible values for the slope using bootstrap confidence intervals\n\n\n## Exploratory data analysis\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nheb <- read_csv(\"../data/HEBIncome.csv\") |> \n  mutate(Avg_Income_K = Avg_Household_Income/1000)\n\ngf_point(Number_Organic ~ Avg_Income_K, data = heb, alpha = 0.7) |> \n  gf_labs(\n    x = \"Average Household Income (in thousands)\",\n    y = \"Number of Organic Vegetables\",\n  ) |> \n  gf_refine(scale_x_continuous(labels = label_dollar()))\n```\n\n::: {.cell-output-display}\n![](03-slr-sbi_files/figure-revealjs/unnamed-chunk-1-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n## Modeling {.midi}\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nheb_fit <- lm(Number_Organic ~ Avg_Income_K, data = heb)\n\ntidy(heb_fit) |>\n  kable(digits=2) #neatly format table to 2 digits\n```\n\n::: {.cell-output-display}\n\n\n|term         | estimate| std.error| statistic| p.value|\n|:------------|--------:|---------:|---------:|-------:|\n|(Intercept)  |   -14.72|      9.30|     -1.58|    0.12|\n|Avg_Income_K |     0.96|      0.13|      7.50|    0.00|\n\n\n:::\n:::\n\n\n\n\n. . .\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n-   **Intercept:** HEBs in Zip Codes with an average household income of \\$0 are expected to have -14.72 organic vegetable options, on average.\n    -   Is this interpretation useful?\n-   **Slope:** For each additional \\$1,000 in average household income, we expect the number of organic options available at nearby HEBs to increase by 0.96, on average.\n\n## From sample to population {.midi}\n\n> For each additional $1,000 in average household income, we expect the number of organic options available at nearby HEBs to increase by 0.96, on average.\n\n<br>\n\n-   Estimate is valid for the single sample of 37 HEBs\n-   What if we're not interested quantifying the relationship between the size and price of a house in this single sample?\n-   What if we want to say something about the relationship between these variables for all supermarkets in America?\n\n## Statistical inference\n\n-   **Statistical inference** refers to ideas, methods, and tools for to generalizing the single observed sample to make statements (inferences) about the population it comes from\n\n-   For our inferences to be valid, the sample should be random and representative of the population we're interested in\n\n## Sampling is natural {.midi}\n\n![](images/03/soup.png){fig-alt=\"Illustration of a bowl of soup\" fig-align=\"center\"}\n\n-   When you taste a spoonful of soup and decide the spoonful you tasted isn't salty enough, that's exploratory analysis\n-   If you generalize and conclude that your entire soup needs salt, that's an inference\n-   For your inference to be valid, the spoonful you tasted (the sample) needs to be representative of the entire pot (the population)\n\n## Confidence interval via bootstrapping {.midi}\n\n-   Bootstrap new samples from the original sample\n-   Fit models to each of the samples and estimate the slope\n-   Use features of the distribution of the bootstrapped slopes to construct a confidence interval\n\n## Inference for simple linear regression\n\n::: incremental\n\n-   Calculate a confidence interval for the slope, $\\beta_1$\n\n-   Conduct a hypothesis test for the slope, $\\beta_1$\n\n-   Why not $\\beta_0$?\n\n-   We can but it isn't super interesting typically\n\n:::\n\n. . .\n\n::: question\n\n- What is a confidence interval?\n\n- What is a hypothesis test?\n:::\n\n# Confidence interval for the slope\n\n## Confidence interval {.midi}\n\n::: incremental\n-   **Confidence interval**: plausible range of values for a population parameter\n-   single point estimate $\\implies$ fishing in a murky lake with a spear\n-   confidence interval $\\implies$ fishing with a net\n    -   We can throw a spear where we saw a fish but we will probably miss, if we toss a net in that area, we have a good chance of catching the fish\n    -  If we report a point estimate, we probably will not hit the exact population parameter, but if we report a range of plausible values we have a good shot at capturing the parameter\n    -   High confidence $\\implies$ wider interval (larger net)\n-   Remember: single CI $\\implies$ either you hit parameter or you don't\n    -   [Favorite Visualization](https://rpsychologist.com/d3/ci/)\n:::\n\n## Confidence interval for the slope {.midi}\n\nA confidence interval will allow us to make a statement like \"*For each \\$1K in average income, the model predicts the number of organic vegetables available at local supermarkets to be higher, on average, by 0.96, plus or minus X options.*\"\n\n. . .\n\n-   Should X be 1? 2? 3?\n\n-   If we were to take another sample of 37 would we expect the slope calculated based on that sample to be exactly 0.96? Off by 1? 2? 3?\n\n-   The answer depends on how variable (from one sample to another sample) the sample statistic (the slope) is\n\n-   We need a way to quantify the variability of the sample statistic\n\n## Quantify the variability of the slope {.midi}\n\n**for estimation**\n\n::: incremental\n-   Two approaches:\n    1.  Via simulation (what we'll do today)\n    2.  Via mathematical models (what we'll do soon)\n-   **Bootstrapping** to quantify the variability of the slope for the purpose of estimation:\n    -   Generate new samples by sampling with replacement from the original sample\n    -   Fit models to each of the new samples and estimate the slope\n    -   Use features of the distribution of the bootstrapped slopes to construct a confidence interval\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n## Original Sample\n\n<!-- Fix the scales for these slides, so the difference in slopes is easier to see-->\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slr-sbi_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Bootstrap sample 1\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slr-sbi_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n\n## Bootstrap sample 2\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slr-sbi_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Bootstrap sample 3\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slr-sbi_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n\n## Bootstrap sample 4\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slr-sbi_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n\n## Bootstrap sample 5\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slr-sbi_files/figure-revealjs/unnamed-chunk-10-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Bootstrap samples 1 - 5\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slr-sbi_files/figure-revealjs/unnamed-chunk-11-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Bootstrap samples 1 - 100\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slr-sbi_files/figure-revealjs/unnamed-chunk-12-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Slopes of bootstrap samples\n\n::: question\n**Fill in the blank:** For each additional \\$1k in average household income, the model predicts the number of organic vegetables available to be higher, on average, by 0.96, plus or minus \\_\\_\\_.\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slr-sbi_files/figure-revealjs/unnamed-chunk-13-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n## Slopes of bootstrap samples\n\n::: question\n**Fill in the blank:** For each additional \\$1k in average household income, the model predicts the number of organic vegetables available to be higher, on average, by 0.96, plus or minus \\_\\_\\_.\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slr-sbi_files/figure-revealjs/unnamed-chunk-14-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n## Confidence level\n\n::: question\nHow confident are you that the true slope is between 0.8 and 1.2? How about 0.9 and 1.0? How about 1.0 and 1.4?\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slr-sbi_files/figure-revealjs/unnamed-chunk-15-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n## 95% confidence interval {.smaller}\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slr-sbi_files/figure-revealjs/unnamed-chunk-16-1.png){fig-align='center' width=70%}\n:::\n:::\n\n\n\n\n::: incremental\n-   **95% bootstrapped confidence interval**: bounded by the middle 95% of the bootstrap distribution\n-   We are 95% confident that for each additional \\$1K in average household income, the model predicts the number of organic vegetables options at local supermarkets to be higher, on average, by 0.81 to 1.31.\n:::\n\n## Computing the CI for the slope I\n\nCalculate the observed slope:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(infer) # package that does Simulation-Based Inference\n\nobserved_fit <- heb |>\n  specify(Number_Organic ~ Avg_Income_K) |>\n  fit()\n\nobserved_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 2\n  term         estimate\n  <chr>           <dbl>\n1 intercept     -14.7  \n2 Avg_Income_K    0.959\n```\n\n\n:::\n:::\n\n\n\n\n## Computing the CI for the slope II {.smaller}\n\nTake `100` bootstrap samples and fit models to each one:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|1,5,6\"}\nset.seed(1120)\n\nboot_fits <- heb |>\n  specify(Number_Organic ~ Avg_Income_K) |>\n  generate(reps = 100, type = \"bootstrap\") |>\n  fit()\n\nboot_fits\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 200 Ã— 3\n# Groups:   replicate [100]\n   replicate term         estimate\n       <int> <chr>           <dbl>\n 1         1 intercept     -40.9  \n 2         1 Avg_Income_K    1.25 \n 3         2 intercept     -23.9  \n 4         2 Avg_Income_K    1.09 \n 5         3 intercept     -18.6  \n 6         3 Avg_Income_K    1.02 \n 7         4 intercept      -1.96 \n 8         4 Avg_Income_K    0.828\n 9         5 intercept     -15.1  \n10         5 Avg_Income_K    0.951\n# â„¹ 190 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Computing the CI for the slope III\n\n**Percentile method:** Compute the 95% CI as the middle 95% of the bootstrap distribution:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|5\"}\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\" #default method\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 3\n  term         lower_ci upper_ci\n  <chr>           <dbl>    <dbl>\n1 Avg_Income_K    0.822     1.27\n2 intercept     -34.5      -2.56\n```\n\n\n:::\n:::\n\n\n\n\nComplete Exercises 3-6\n\n## Precision vs. accuracy\n\n::: question\nIf we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval? What drawbacks are associated with using a wider interval?\n:::\n\n. . .\n\n![](images/03/garfield.png)\n\n## Precision vs. accuracy\n\n::: question\nHow can we get best of both worlds -- high precision and high accuracy?\n:::\n\n## Changing confidence level\n\n::: question\nHow would you modify the following code to calculate a 90% confidence interval? How would you modify it for a 99% confidence interval?\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|4\"}\nget_confidence_interval(\n  boot_fits, \n  point_estimate = observed_fit, \n  level = 0.95,\n  type = \"percentile\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 3\n  term         lower_ci upper_ci\n  <chr>           <dbl>    <dbl>\n1 Avg_Income_K    0.822     1.27\n2 intercept     -34.5      -2.56\n```\n\n\n:::\n:::\n\n\n\n\n## Changing confidence level {.midi}\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n## confidence level: 90%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.90, type = \"percentile\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 3\n  term         lower_ci upper_ci\n  <chr>           <dbl>    <dbl>\n1 Avg_Income_K    0.829     1.23\n2 intercept     -31.7      -3.76\n```\n\n\n:::\n\n```{.r .cell-code}\n## confidence level: 99%\nget_confidence_interval(\n  boot_fits, point_estimate = observed_fit, \n  level = 0.99, type = \"percentile\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 3\n  term         lower_ci upper_ci\n  <chr>           <dbl>    <dbl>\n1 Avg_Income_K    0.795    1.36 \n2 intercept     -43.3     -0.535\n```\n\n\n:::\n:::\n\n\n\n\nComplete Exercises 7-11.\n\n\n\n# Randomization Test for Slope: Topics\n\n-   Evaluate a claim about the slope using hypothesis testing\n\n<!-- -   Define mathematical models to conduct inference for slope -->\n\n\n## The regression model\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nheb_fit <- lm(Number_Organic ~ Avg_Income_K, data = heb)\n\ntidy(heb_fit) |>\n  kable(digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n|term         | estimate| std.error| statistic| p.value|\n|:------------|--------:|---------:|---------:|-------:|\n|(Intercept)  |   -14.72|      9.30|     -1.58|    0.12|\n|Avg_Income_K |     0.96|      0.13|      7.50|    0.00|\n\n\n:::\n:::\n\n\n\n\n. . .\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n**Slope:** For each additional \\$1,000 in average household income, we expect the number of organic options available at nearby HEBs to increase by 0.96, on average.\n\n\n## Research question and hypotheses\n\n\"Do the data provide sufficient evidence that $\\beta_1$ (the true slope for the population) is different from 0?\"\n\n. . .\n\n**Null hypothesis**: there is no linear relationship between `Number_Organic` and `Avg_Income_K`\n\n$$\nH_0: \\beta_1 = 0\n$$\n\n. . .\n\n**Alternative hypothesis**: there is a linear relationship between `Number_Organic` and `Avg_Income_K`\n\n$$\nH_A: \\beta_1 \\ne 0\n$$\n\n## Hypothesis testing as a court trial\n\n::: incremental\n-   **Null hypothesis**, $H_0$: Defendant is innocent\n-   **Alternative hypothesis**, $H_A$: Defendant is guilty\n-   **Present the evidence:** Collect data\n-   **Judge the evidence:** \"Could these data plausibly have happened by chance if the null hypothesis were true?\"\n    -   Yes: Fail to reject $H_0$\n    -   No: Reject $H_0$\n-   Not guilty $\\neq$ innocent $\\implies$ why we say \"fail to reject the null\" rather than \"accept the null\"\n:::\n\n## Hypothesis testing framework {.midi}\n\n::: incremental\n-   Start with a null hypothesis, $H_0$ that represents the status quo\n-   Set an alternative hypothesis, $H_A$ that represents the research question, i.e. claim we're testing\n-   Under the assumption that the null hypothesis is true, calculate a **p-value** (probability of getting outcome or outcome even more favorable to the alternative)\n    -   if the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\n    -   if they do, then reject the null hypothesis in favor of the alternative\n:::\n\nComplete Exercise 12\n\n## Quantify the variability of the slope {.midi}\n\n**for testing**\n\n::: incremental\n-   Two approaches:\n    1.  Via simulation\n    2.  Via mathematical models\n-   Use **Randomization** to quantify the variability of the slope for the purpose of testing, *under the assumption that the null hypothesis is true*:\n    -   Simulate new samples from the original sample via permutation\n    -   Fit models to each of the samples and estimate the slope\n    -   Use features of the distribution of the permuted slopes to conduct a hypothesis test\n:::\n\n## Permutation, described {.smaller}\n\n::: columns\n::: {.column width=\"40%\"}\n-   Use permuting to simulate data under the assumption the null hypothesis is true and measure the natural variability in the data due to sampling, [**not**]{.underline} due to variables being correlated\n    -   Permute/shuffle response variable to eliminate any existing relationship with explanatory variable\n-   Each `Number_Organic` value is randomly assigned to the `Avg_Household_K`, i.e. `Number_Organic` and `Avg_Household_K` are no longer matched for a given store\n:::\n\n::: {.column width=\"60%\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 37 Ã— 3\n   Number_Organic_Original Number_Organic_Permuted Avg_Income_K\n                     <dbl>                   <dbl>        <dbl>\n 1                      36                      73         71.2\n 2                       4                      29         34.2\n 3                      28                      35         71.2\n 4                      31                      38         48.8\n 5                      78                      78         78.1\n 6                      14                      14         40.5\n 7                      12                      82         38.2\n 8                      18                      31         50.4\n 9                      38                       4         49.4\n10                      84                      12         66.1\n# â„¹ 27 more rows\n```\n\n\n:::\n:::\n\n\n\n:::\n:::\n\n## Permutation, visualized\n\n::: columns\n::: {.column width=\"50%\"}\n-   Each of the observed values for `area` (and for `price`) exist in both the observed data plot as well as the permuted `price` plot\n-   Permuting removes the relationship between `area` and `price`\n:::\n\n::: {.column width=\"50%\"}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slr-sbi_files/figure-revealjs/unnamed-chunk-25-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n:::\n:::\n\n## Permutation, repeated\n\nRepeated permutations allow for quantifying the variability in the slope under the condition that there is no linear relationship (i.e., that the null hypothesis is true)\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slr-sbi_files/figure-revealjs/unnamed-chunk-26-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n## Concluding the hypothesis test {.smaller}\n\n::: question\nIs the observed slope of $\\hat{\\beta_1} = 0.96$ (or an even more extreme slope) a likely outcome under the null hypothesis that $\\beta = 0$? What does this mean for our original question: \"Do the data provide sufficient evidence that $\\beta_1$ (the true slope for the population) is different from 0?\"\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slr-sbi_files/figure-revealjs/unnamed-chunk-27-1.png){fig-align='center' width=60%}\n:::\n:::\n\n\n\n\n\n\n## Permutation pipeline I\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|1|3|4\"}\nset.seed(1218)\n\nheb |>\n  specify(Number_Organic ~ Avg_Income_K)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nResponse: Number_Organic (numeric)\nExplanatory: Avg_Income_K (numeric)\n# A tibble: 37 Ã— 2\n   Number_Organic Avg_Income_K\n            <dbl>        <dbl>\n 1             36         71.2\n 2              4         34.2\n 3             28         71.2\n 4             31         48.8\n 5             78         78.1\n 6             14         40.5\n 7             12         38.2\n 8             18         50.4\n 9             38         49.4\n10             84         66.1\n# â„¹ 27 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Permutation pipeline II\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|5\"}\nset.seed(1218)\n\nheb |>\n  specify(Number_Organic ~ Avg_Income_K) |>\n  hypothesize(null = \"independence\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nResponse: Number_Organic (numeric)\nExplanatory: Avg_Income_K (numeric)\nNull Hypothesis: independence\n# A tibble: 37 Ã— 2\n   Number_Organic Avg_Income_K\n            <dbl>        <dbl>\n 1             36         71.2\n 2              4         34.2\n 3             28         71.2\n 4             31         48.8\n 5             78         78.1\n 6             14         40.5\n 7             12         38.2\n 8             18         50.4\n 9             38         49.4\n10             84         66.1\n# â„¹ 27 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Permutation pipeline III\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|6\"}\nset.seed(1218)\n\nheb |>\n  specify(Number_Organic ~ Avg_Income_K) |>\n  hypothesize(null = \"independence\") |>\n  generate(reps = 1000, type = \"permute\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nResponse: Number_Organic (numeric)\nExplanatory: Avg_Income_K (numeric)\nNull Hypothesis: independence\n# A tibble: 37,000 Ã— 3\n# Groups:   replicate [1,000]\n   Number_Organic Avg_Income_K replicate\n            <dbl>        <dbl>     <int>\n 1             38         71.2         1\n 2             56         34.2         1\n 3             28         71.2         1\n 4             14         48.8         1\n 5             29         78.1         1\n 6             36         40.5         1\n 7             84         38.2         1\n 8             18         50.4         1\n 9             96         49.4         1\n10             26         66.1         1\n# â„¹ 36,990 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Permutation pipeline IV\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|7\"}\nset.seed(1218)\n\nheb |>\n  specify(Number_Organic ~ Avg_Income_K) |>\n  hypothesize(null = \"independence\") |>\n  generate(reps = 1000, type = \"permute\") |>\n  fit()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2,000 Ã— 3\n# Groups:   replicate [1,000]\n   replicate term         estimate\n       <int> <chr>           <dbl>\n 1         1 intercept     47.8   \n 2         1 Avg_Income_K   0.0555\n 3         2 intercept     58.0   \n 4         2 Avg_Income_K  -0.0914\n 5         3 intercept     57.3   \n 6         3 Avg_Income_K  -0.0817\n 7         4 intercept     78.9   \n 8         4 Avg_Income_K  -0.394 \n 9         5 intercept     34.8   \n10         5 Avg_Income_K   0.244 \n# â„¹ 1,990 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Permutation pipeline V\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|3\"}\nset.seed(1218)\n\nnull_dist <- heb |>\n  specify(Number_Organic ~ Avg_Income_K) |>\n  hypothesize(null = \"independence\") |>\n  generate(reps = 1000, type = \"permute\") |>\n  fit()\n```\n:::\n\n\n\n\n## Visualize the null distribution\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|2\"}\nnull_dist |>\n  filter(term == \"Avg_Income_K\") |>\n  gf_histogram(~estimate, color = \"white\")\n```\n\n::: {.cell-output-display}\n![](03-slr-sbi_files/figure-revealjs/unnamed-chunk-33-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\nComplete Exercises 13 and 14.\n\n## Reason around the p-value {.smaller}\n\n::: question\nIn a world where the there is no relationship between the the number of organic food options and the nearby average household income ($\\beta_1 = 0$), what is the probability that we observe a sample of 37 stores where the slope fo the model predicting the number of organic options from average household income is 0.96 or even more extreme?\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03-slr-sbi_files/figure-revealjs/unnamed-chunk-34-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n## Compute the p-value\n\n::: question\nWhat does this warning mean?\n:::\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nget_p_value(\n  null_dist,\n  obs_stat = observed_fit, # Same as from confidence intervals\n  direction = \"two-sided\"\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Please be cautious in reporting a p-value of 0. This result is an approximation\nbased on the number of `reps` chosen in the `generate()` step.\nâ„¹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\nPlease be cautious in reporting a p-value of 0. This result is an approximation\nbased on the number of `reps` chosen in the `generate()` step.\nâ„¹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 2\n  term         p_value\n  <chr>          <dbl>\n1 Avg_Income_K       0\n2 intercept          0\n```\n\n\n:::\n:::\n\n\n\n\nComplete Exercises 15 and 16.\n\n## Recap {.smaller}\n\n-   **Population:** Complete set of observations of whatever we are studying, e.g., people, tweets, photographs, etc. (population size = $N$)\n\n-   **Sample:** Subset of the population, ideally random and representative (sample size = $n$)\n\n-   Sample statistic $\\ne$ population parameter, but if the sample is good, it can be a good estimate\n\n-   **Statistical inference:** Discipline that concerns itself with the development of procedures, methods, and theorems that allow us to extract meaning and information from data that has been generated by stochastic (random) process\n\n## Recap Continued {.smaller}\n\n-   **Estimation:** Use data to compute point estimate\n\n    +   Report the estimate with a confidence interval, and the width of this interval depends on the variability of sample statistics from different samples from the population\n\n-   **Testing:** Conduct a *hypothesis test*\n\n    +   Assume research question isn't true (Null hypothesis)\n    +   Ask what distribution of test statistic is if null is true\n    +   Ask if your data would be unusual if under this null distribution\n    +   P-value: Probability your data (or even stronger evidence) was obstained from null distribution",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}