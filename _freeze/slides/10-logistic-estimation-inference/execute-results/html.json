{
  "hash": "b53ceda41e6209c200815dbd7d09f05a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Logistic Regression Estimation and Inference\"\nauthor: \"Prof. Eric Friedlander\"\nfooter: \"[ðŸ”— MAT 212 - Winter 2025 -  Schedule](https://mat212wi25.netlify.app/schedule)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: false\n    incremental: false \n    chalkboard: true\nhtml-math-method:\n  method: mathjax\n  url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\nexecute:\n  freeze: auto\n  echo: true\n  cache: false\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib  \n---\n\n\n\n\n\n## Application Exercise {.midi}\n\n::: appex\nðŸ“‹ [AE 10 - Logistic Regression Inference](/ae/ae-10-logistic-inference.qmd)\n\n- Open up AE 10 and complete Exercise 0.\n:::\n\n\n\n## Topics\n\n::: nonincremental\n-   Estimating coefficients in logistic regression\n-   Checking model conditions for logistic regression\n-   Inference for coefficients in logistic regression\n:::\n\n## Computational setup\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(ggformula)\nlibrary(openintro)\nlibrary(knitr)\nlibrary(kableExtra)  # for table embellishments\nlibrary(Stat2Data)   # for empirical logit\nlibrary(countdown)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))\n```\n:::\n\n\n\n# Data\n\n## Risk of coronary heart disease {.midi}\n\nThis data set is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. We want to examine the relationship between various health characteristics and the risk of having heart disease.\n\n-   `TenYearCHD`:\n\n    -   1: High risk of having heart disease in next 10 years\n    -   0: Not high risk of having heart disease in next 10 years\n\n-   `age`: Age at exam time (in years)\n\n-   `currentSmoker`: 0 = nonsmoker, 1 = smoker\n\n## Data prep\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nheart_disease <- read_csv(\"../data/framingham.csv\") |>\n  select(TenYearCHD, age, currentSmoker) |>\n  drop_na() |>\n  mutate(currentSmoker = as.factor(currentSmoker))\n\nheart_disease |> head() |> kable()\n```\n\n::: {.cell-output-display}\n\n\n| TenYearCHD| age|currentSmoker |\n|----------:|---:|:-------------|\n|          0|  39|0             |\n|          0|  46|0             |\n|          0|  48|1             |\n|          1|  61|1             |\n|          0|  46|1             |\n|          0|  43|0             |\n\n\n:::\n:::\n\n\n\n# Estimating coefficients\n\n## Statistical model {.midi}\n\nThe form of the statistical model for logistic regression is\n\n$$\n\\log\\Big(\\frac{\\pi}{1-\\pi}\\Big) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\dots + \\beta_pX_p\n$$\n\nwhere $\\pi$ is the probability $Y = 1$.\n\n. . .\n\nNotice there is no error term when writing the statistical model for logistic regression. Why?\n\n-   The statistical model is the \"data-generating\" model\n-   Each individual observed $Y$ is generated from a *Bernoulli distribution*, $Bernoulli(\\pi)$\n-   Therefore, the randomness is not produced by an error term but rather in the distribution used to generate $Y$\n\n## Bernoulli Distribution {.smaller}\n\n-   Think of two possible outcomes:\n  -   1 = \"Success\" which occurs with probability $\\pi$\n  -   0 = \"Failure\" which occurs with probability $1-\\pi$\n-   We can think of each of our observations as having a Bernoulli distribution with mean $\\pi_i$\n-   Our logistic regression model is changing $\\pi_i$ (the probability of success) for each new observation\n-   The probability that we got our data, given our model is the truth, is then called the *Likelihood* $$L = \\prod_{i=1}^n \\pi_i^{y_i}(1-\\pi_i)^{1-y_i}$$\n\n## Log Likelihood Function {.smaller}\n\n**Log-Likelihood Function**: the log of the likelihood function is easier to work with and has the same maxima and minima!\n\n$$\n\\log L = \\sum\\limits_{i=1}^n[y_i \\log(\\hat{\\pi}_i) + (1 - y_i)\\log(1 - \\hat{\\pi}_i)]\n$$\n\nwhere\n\n$$\\hat{\\pi} = \\frac{\\exp\\{\\hat{\\beta}_0 + \\hat{\\beta}_1X_1 + \\dots + \\hat{\\beta}_pX_p\\}}{1 + \\exp\\{\\hat{\\beta}_0 + \\hat{\\beta}_1X_1 + \\dots + \\hat{\\beta}_pX_p\\}}$$\n\n. . .\n\n-   The coefficients $\\hat{\\beta}_0, \\ldots, \\hat{\\beta}_p$ are estimated using maximum likelihood estimation\n\n-   Basic idea: Find the values of $\\hat{\\beta}_0, \\ldots, \\hat{\\beta}_p$ that give the observed data the maximum probability of occurring\n\n## Maximum Likelihood Estimation\n\n-   This is called **maximum likelihood estimation** and is EXTREMELY common in statistics and data science\n\n  -   Need a strong foundation in probability and applied mathematics to fully understand\n  \n  -   Logistic regression: maximum found through **numerical methods** (clever computer algorithms that approximate the maximum)\n  \n  -   Linear regression: maximum found through **calculus**\n  \n\n. . .\n\nComplete Exercise 1.  \n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"countdown\" id=\"timer_f859279a\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>\n```\n\n:::\n:::\n\n\n\n# Conditions\n\n## The models {.smaller}\n\nModel 1: Let's predict `TenYearCHD` from `currentSmoker`:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrisk_fit <- glm(TenYearCHD ~ currentSmoker, \n      data = heart_disease, family = \"binomial\")\n\ntidy(risk_fit, conf.int = TRUE) |> \n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term           | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:--------------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept)    |   -1.774|     0.061|   -28.936|   0.000|   -1.896|    -1.656|\n|currentSmoker1 |    0.108|     0.086|     1.266|   0.206|   -0.059|     0.276|\n\n\n:::\n:::\n\n\n\nModel 2: Let's predict `TenYearCHD` from `age`:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrisk_fit <- glm(TenYearCHD ~ age, \n      data = heart_disease, family = \"binomial\")\n\ntidy(risk_fit, conf.int = TRUE) |> \n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:-----------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept) |   -5.561|     0.284|   -19.599|       0|   -6.124|    -5.011|\n|age         |    0.075|     0.005|    14.178|       0|    0.064|     0.085|\n\n\n:::\n:::\n\n\n\n## Conditions for logistic regression\n\n1.  **Linearity:** The log-odds have a linear relationship with the predictors.\n\n2.  **Randomness:** The data were obtained from a random process.\n\n3.  **Independence:** The observations are independent from one another.\n\n## Empirical logit\n\nThe **empirical logit** is the log of the observed odds:\n\n$$\n\\text{logit}(\\hat{p}) = \\log\\Big(\\frac{\\hat{p}}{1 - \\hat{p}}\\Big) = \\log\\Big(\\frac{\\# \\text{Yes}}{\\# \\text{No}}\\Big)\n$$\n\n## Calculating empirical logit (categorical predictor)\n\nIf the predictor is categorical, we can calculate the empirical logit for each level of the predictor.\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n\n|currentSmoker | TenYearCHD|   n|      prop| emp_logit|\n|:-------------|----------:|---:|---------:|---------:|\n|0             |          1| 311| 0.1449883| -1.774462|\n|1             |          1| 333| 0.1589499| -1.666062|\n\n\n:::\n:::\n\n\n\n. . .\n\nComplete Exercise 2.\n\n## Calculating empirical logit (quantitative predictor)\n\n1.  Divide the range of the predictor into intervals with approximately equal number of cases. (If you have enough observations, use 5 - 10 intervals.)\n\n2.  Compute the empirical logit for each interval\n\n. . .\n\nYou can then calculate the mean value of the predictor in each interval and create a plot of the empirical logit versus the mean value of the predictor in each interval.\n\n## Empirical logit plot in R (quantitative predictor)\n\nCreated using `dplyr` and `ggplot` functions.\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](10-logistic-estimation-inference_files/figure-revealjs/unnamed-chunk-8-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n## Empirical logit plot in R (quantitative predictor)\n\nCreated using `dplyr` and `ggformula` functions.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nheart_disease |> \n  mutate(age_bin = cut_interval(age, n = 10)) |>\n  group_by(age_bin) |>\n  mutate(mean_age = mean(age)) |>\n  count(mean_age, TenYearCHD) |>\n  mutate(prop = n/sum(n)) |>\n  filter(TenYearCHD == \"1\") |>\n  mutate(emp_logit = log(prop/(1-prop))) |>\n  gf_point(emp_logit ~ mean_age)  |>  \n  gf_smooth(method = \"lm\", se = FALSE) |> \n  gf_labs(x = \"Mean Age\", \n       y = \"Empirical logit\")\n```\n:::\n\n\n\n## Empirical logit plot in R (quantitative predictor)\n\nUsing the `emplogitplot1` function from the **Stat2Data** R package\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemplogitplot1(TenYearCHD ~ age, \n              data = heart_disease, \n              ngroups = 10)\n```\n\n::: {.cell-output-display}\n![](10-logistic-estimation-inference_files/figure-revealjs/unnamed-chunk-10-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n## Checking linearity\n\nâœ… The linearity condition is satisfied. There is a linear relationship between the empirical logit and the predictor variables.\n\n. . .\n\nComplete Exercise 3.\n\n## Checking randomness\n\nWe can check the randomness condition based on the context of the data and how the observations were collected.\n\n-   Was the sample randomly selected?\n-   Did the successes and failures occur from a random process?\n\n. . .\n\nâœ… The randomness condition is satisfied. Who does and does not develop heart disease occurs from a random process.\n\n## Checking independence\n\n-   We can check the independence condition based on the context of the data and how the observations were collected.\n-   Independence is most often violated if the data were collected over time or there is a strong spatial relationship between the observations.\n\n. . .\n\nâœ… The independence condition is satisfied. It is reasonable to conclude that the participants' health characteristics are independent of one another.\n\n## Modeling risk of coronary heart disease\n\n:::question\nWhat's wrong with this code?\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|3,4\"}\nrisk_fit <- glm(TenYearCHD ~ age, data = heart_disease, \n                family = \"binomial\") |> \n  tidy() |> \n  kable()\n```\n:::\n\n\n\n## Modeling risk of coronary heart disease\n\nUsing `age`:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrisk_fit <- glm(TenYearCHD ~ age, data = heart_disease, \n                family = \"binomial\")\n\nrisk_fit |> tidy() |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|term        |   estimate| std.error| statistic| p.value|\n|:-----------|----------:|---------:|---------:|-------:|\n|(Intercept) | -5.5610898| 0.2837460| -19.59883|       0|\n|age         |  0.0746501| 0.0052651|  14.17821|       0|\n\n\n:::\n:::\n\n\n    \n# Inference for Logistic Regression\n\n## Recall: Inference for Linear Regression\n\n-   **t-test:** determine whether $\\beta_1$ (the slope) is different than zero\n-   **ANOVA/F-Test:** To test the full model or to compare nested models\n-   **SSModel/SSE/ $R^2$ / $\\hat{\\sigma}_{\\epsilon}$ :** metrics to try a measure the amount of variability explained by competing models\n\n## Hypothesis test for $\\beta_1$\n\n**Hypotheses:** $H_0: \\beta_1 = 0 \\hspace{2mm} \\text{ vs } \\hspace{2mm} H_a: \\beta_1 \\neq 0$\n\n. . .\n\n**Test Statistic:** $$z = \\frac{\\hat{\\beta}_1 - 0}{SE_{\\hat{\\beta}_1}}$$\n\n$z$ is sometimes called a *Wald statistic* and this test is sometimes called a *Wald Hypothesis Test*.\n\n. . .\n\n**P-value:** $P(|Z| > |z|)$, where $Z \\sim N(0, 1)$, the Standard Normal distribution\n\n## Confidence interval for $\\beta_1$\n\nWe can calculate the **C% confidence interval** for $\\beta_1$ as the following:\n\n$$\n\\Large{\\hat{\\beta}_1 \\pm z^* SE_{\\hat{\\beta}_1}}\n$$\n\nwhere $z^*$ is calculated from the $N(0,1)$ distribution\n\n. . .\n\n::: callout-note\nThis is an interval for the change in the *log-odds* for every one unit increase in $x$\n:::\n\n## Interpretation in terms of the odds\n\nThe change in **odds** for every one unit increase in $x_1$.\n\n$$\n\\Large{\\exp\\{\\hat{\\beta}_1 \\pm z^* SE_{\\hat{\\beta}_1}\\}}\n$$\n\n. . .\n\n**Interpretation:** We are $C\\%$ confident that for every one unit increase in $x_1$, the odds multiply by a factor of $\\exp\\{\\hat{\\beta}_1 - z^* SE_{\\hat{\\beta}_1}\\}$ to $\\exp\\{\\hat{\\beta}_1 + z^* SE_{\\hat{\\beta}_1}\\}$.\n\n## Coefficient for `age` {.midi}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> estimate </th>\n   <th style=\"text-align:right;\"> std.error </th>\n   <th style=\"text-align:right;\"> statistic </th>\n   <th style=\"text-align:right;\"> p.value </th>\n   <th style=\"text-align:right;\"> conf.low </th>\n   <th style=\"text-align:right;\"> conf.high </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> -5.561 </td>\n   <td style=\"text-align:right;\"> 0.284 </td>\n   <td style=\"text-align:right;\"> -19.599 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> -6.124 </td>\n   <td style=\"text-align:right;\"> -5.011 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;background-color: rgba(217, 227, 228, 255) !important;\"> age </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.075 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.005 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 14.178 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.064 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.085 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n. . .\n\n**Hypotheses:**\n\n$$\nH_0: \\beta_{age} = 0 \\hspace{2mm} \\text{ vs } \\hspace{2mm} H_a: \\beta_{age} \\neq 0\n$$\n\n## Coefficient for `age` {.midi}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> estimate </th>\n   <th style=\"text-align:right;\"> std.error </th>\n   <th style=\"text-align:right;\"> statistic </th>\n   <th style=\"text-align:right;\"> p.value </th>\n   <th style=\"text-align:right;\"> conf.low </th>\n   <th style=\"text-align:right;\"> conf.high </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> -5.561 </td>\n   <td style=\"text-align:right;\"> 0.284 </td>\n   <td style=\"text-align:right;\"> -19.599 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> -6.124 </td>\n   <td style=\"text-align:right;\"> -5.011 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;background-color: rgba(217, 227, 228, 255) !important;\"> age </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.075 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.005 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 14.178 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.064 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.085 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n**Test statistic:**\n\n$$z = \\frac{0.0747 - 0}{0.00527} \\approx 14.178$$\n\nNote: rounding errors!\n\n## Coefficient for `age` {.midi}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> estimate </th>\n   <th style=\"text-align:right;\"> std.error </th>\n   <th style=\"text-align:right;\"> statistic </th>\n   <th style=\"text-align:right;\"> p.value </th>\n   <th style=\"text-align:right;\"> conf.low </th>\n   <th style=\"text-align:right;\"> conf.high </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> -5.561 </td>\n   <td style=\"text-align:right;\"> 0.284 </td>\n   <td style=\"text-align:right;\"> -19.599 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> -6.124 </td>\n   <td style=\"text-align:right;\"> -5.011 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;background-color: rgba(217, 227, 228, 255) !important;\"> age </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.075 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.005 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 14.178 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.064 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.085 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n**P-value:**\n\n$$\nP(|Z| > |14.178|) \\approx 0\n$$\n\n. . .\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n2 * pnorm(14.178,lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1.253689e-45\n```\n\n\n:::\n:::\n\n\n\n## Coefficient for `age` {.midi}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> estimate </th>\n   <th style=\"text-align:right;\"> std.error </th>\n   <th style=\"text-align:right;\"> statistic </th>\n   <th style=\"text-align:right;\"> p.value </th>\n   <th style=\"text-align:right;\"> conf.low </th>\n   <th style=\"text-align:right;\"> conf.high </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> -5.561 </td>\n   <td style=\"text-align:right;\"> 0.284 </td>\n   <td style=\"text-align:right;\"> -19.599 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> -6.124 </td>\n   <td style=\"text-align:right;\"> -5.011 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;background-color: rgba(217, 227, 228, 255) !important;\"> age </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.075 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.005 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 14.178 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.064 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.085 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n**Conclusion:**\n\nThe p-value is very small, so we reject $H_0$. The data provide sufficient evidence that age is a statistically significant predictor of whether someone will develop heart disease in the next 10 years.\n\n## CI for `age`\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> estimate </th>\n   <th style=\"text-align:right;\"> std.error </th>\n   <th style=\"text-align:right;\"> statistic </th>\n   <th style=\"text-align:right;\"> p.value </th>\n   <th style=\"text-align:right;\"> conf.low </th>\n   <th style=\"text-align:right;\"> conf.high </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> -5.561 </td>\n   <td style=\"text-align:right;\"> 0.284 </td>\n   <td style=\"text-align:right;\"> -19.599 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> -6.124 </td>\n   <td style=\"text-align:right;\"> -5.011 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;background-color: rgba(217, 227, 228, 255) !important;\"> age </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.075 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.005 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 14.178 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.064 </td>\n   <td style=\"text-align:right;background-color: rgba(217, 227, 228, 255) !important;\"> 0.085 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\nWe are 95% confident that for each additional year of age, the change in the *log-odds* of someone developing heart disease in the next 10 years is between 0.064 and 0.085.\n\n. . .\n\nWe are 95% confident that for each additional year of age, the *odds* of someone developing heart disease in the next 10 years will increase by a factor of $\\exp(0.064) \\approx 1.077$ to $\\exp(0.085)\\approx 1.089$.\n\n. . .\n\nComplete Exercises 4-7.\n\n## Recall: Inference for Linear Regression\n\n-   **t-test:** determine whether $\\beta_1$ (the slope) is different than zero\n-   **ANOVA/F-Test:** To test the full model or to compare nested models\n-   **SSModel/SSE/ $R^2$ / $\\hat{\\sigma}_{\\epsilon}$ :** metrics to try a measure the amount of variability explained by competing models\n\n## Recall: Likelihood\n\n$$\nL = \\prod_{i=1}^n\\hat{\\pi}_i^{y_i}(1 - \\hat{\\pi}_i)^{1 - y_i}\n$$\n\n-   Intuition: probability of obtaining our data given a certain set of parameters\n\n$$\nL(\\hat{\\beta}_0, \\ldots, \\hat{\\beta}_p) = \\prod_{i=1}^n\\hat{\\pi}_i(\\hat{\\beta}_0, \\ldots, \\hat{\\beta}_p)^{y_i}(1 - \\hat{\\pi}_i(\\hat{\\beta}_0, \\ldots, \\hat{\\beta}_p))^{1 - y_i}\n$$\n\n## Recall: Log-Likelihood\n\nTaking the log makes the likelihood easier to work with and **doesn't change which $\\beta$'s maximize it**.\n\n$$\n\\log L = \\sum\\limits_{i=1}^n[y_i \\log(\\hat{\\pi}_i) + (1 - y_i)\\log(1 - \\hat{\\pi}_i)]\n$$\n\n## Log-Likelihood to Deviance\n\n-   The log-likelihood measures of how well the model fits the data\n\n-   Higher values of $\\log L$ are better\n\n-   **Deviance** = $-2 \\log L$\n\n    -   $-2 \\log L$ follows a $\\chi^2$ distribution with 1 degree of freedom\n    \n    -   Think of deviace as the analog of the residual sum of squares (SSE) in linear regression\n\n\n\n## Calculate deviance for our model:\n\nWe can use our trusty ol' `glance` function\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrisk_fit |>  glance() |> kable()\n```\n\n::: {.cell-output-display}\n\n\n| null.deviance| df.null|    logLik|     AIC|      BIC| deviance| df.residual| nobs|\n|-------------:|-------:|---------:|-------:|--------:|--------:|-----------:|----:|\n|      3612.209|    4239| -1698.305| 3400.61| 3413.314|  3396.61|        4238| 4240|\n\n\n:::\n:::\n\n\n\n. . .\n\nComplete Exercise 8.\n\n## Comparing nested models\n\n-   Suppose there are two models:\n\n    -   Reduced Model includes only an intercept $\\beta_0$\n    -   Full Model includes $\\beta_1$\n\n-   We want to test the hypotheses\n\n    $$\n    \\begin{aligned}\n    H_0&: \\beta_{1} = 0\\\\\n    H_A&: \\beta_1 \\neq 0\n    \\end{aligned}\n    $$\n\n-   To do so, we will use something called a **Likelihood Ratio test (LRT)**, also known as the **Drop-in-deviance test**\n\n## Likelihood Ratio Test (LRT) {.smaller}\n\n**Hypotheses:**\n\n$$\n\\begin{aligned}\nH_0&: \\beta_1 = 0 \\\\\nH_A&: \\beta_1 \\neq 0\n\\end{aligned}\n$$\n\n. . .\n\n**Test Statistic:** $$G = (-2 \\log L_{reduced}) - (-2 \\log L_{full})$$\n\nSometimes written as $$G = (-2 \\log L_0) - (-2 \\log L)$$\n\n. . .\n\n**P-value:** $P(\\chi^2 > G)$, calculated using a $\\chi^2$ distribution with 1 degree of freedom\n\n## $\\chi^2$ distribution\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](10-logistic-estimation-inference_files/figure-revealjs/unnamed-chunk-20-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n## Reduced model {.smaller}\n\nFirst model, reduced:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrisk_fit_reduced <- glm(TenYearCHD ~ 1, \n      data = heart_disease, family = \"binomial\",\n      control = glm.control(epsilon = 1e-20)) # Ignore this line\n\nrisk_fit_reduced |> tidy() |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|term        |  estimate| std.error| statistic| p.value|\n|:-----------|---------:|---------:|---------:|-------:|\n|(Intercept) | -1.719879| 0.0427888| -40.19459|       0|\n\n\n:::\n:::\n\n\n\n. . .\n\nSide bar... \n\n::::{.columns}\n:::{.column}\nProbability predicted by model\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nexp(coef(risk_fit_reduced)[1])/(1 + exp(coef(risk_fit_reduced)[1]))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept) \n  0.1518868 \n```\n\n\n:::\n:::\n\n\n:::\n:::{.column}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(mosaic)\ntally(~TenYearCHD, data = heart_disease, format = \"proportion\") |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|TenYearCHD |      Freq|\n|:----------|---------:|\n|0          | 0.8481132|\n|1          | 0.1518868|\n\n\n:::\n:::\n\n\n:::\n::::\n\n## Should we add `age` to the model? {.smaller}\n\nSecond model, full:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nrisk_fit_full <- glm(TenYearCHD ~ age, \n      data = heart_disease, family = \"binomial\")\n\nrisk_fit_full |>  tidy() |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|term        |   estimate| std.error| statistic| p.value|\n|:-----------|----------:|---------:|---------:|-------:|\n|(Intercept) | -5.5610898| 0.2837460| -19.59883|       0|\n|age         |  0.0746501| 0.0052651|  14.17821|       0|\n\n\n:::\n:::\n\n\n\n## Should we add `age` to the model? {.smaller}\n\nCalculate deviance for each model:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndev_reduced <- glance(risk_fit_reduced)$deviance #Use $ instead of select\n\ndev_full <- glance(risk_fit_full)$deviance\n\ndev_reduced\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3612.209\n```\n\n\n:::\n\n```{.r .cell-code}\ndev_full\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3396.61\n```\n\n\n:::\n:::\n\n\n\n## Should we add `age` to the model? {.smaller}\nDrop-in-deviance test statistic:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntest_stat <- dev_reduced - dev_full\n```\n:::\n\n\n\n## Should we add `age` to the model?\n\nCalculate the p-value using a `pchisq()`, with 1 degree of freedom:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npchisq(test_stat, 1, lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 8.249288e-49\n```\n\n\n:::\n:::\n\n\n\n. . .\n\n**Conclusion:** The p-value is very small, so we reject $H_0$. The data provide sufficient evidence that the coefficient of `age` is not equal to 0. Therefore, we should add it to the model.\n\n. . .\n\nComplete Exercises 9-10.\n\n## Drop-in-Deviance test in R {.midi}\n\n-   We can use the **`anova`** function to conduct this test\n\n-   Add **`test = \"Chisq\"`** to conduct the drop-in-deviance test\n\n. . .\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(risk_fit_reduced, risk_fit_full, test = \"Chisq\") |>\n  tidy() |> kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term             | df.residual| residual.deviance| df| deviance| p.value|\n|:----------------|-----------:|-----------------:|--:|--------:|-------:|\n|TenYearCHD ~ 1   |        4239|          3612.209| NA|       NA|      NA|\n|TenYearCHD ~ age |        4238|          3396.610|  1|  215.599|       0|\n\n\n:::\n:::\n\n\n\nComplete Exercises 11-12.\n\n\n\n# Recap\n\n## Recap\n\n-   How do we fit a logistic regression model?\n    -   Maximum likelihood estimation\n    \n-   Logistic regression conditions\n    -   Linearity\n    -   Randomness\n    -   Independence\n\n## Inference for $\\beta_1$\n\n-   Wald Test\n-   Likelihood Ratio Test\n    -   More reliable than Wald\n    -   More computationally taxing\n    -   Deviance: think of like SSE\n-   Next time: Multiple predictors!",
    "supporting": [
      "10-logistic-estimation-inference_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/countdown-0.4.0/countdown.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/countdown-0.4.0/countdown.js\"></script>\n<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}