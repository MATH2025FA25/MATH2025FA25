{
  "hash": "4c06d8256255a91c220004cb39517a23",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"SLR: Transformations\"\nauthor: \"Prof. Eric Friedlander\"\nfooter: \"[🔗 MAT 212 - Winter 2025 -  Schedule](https://mat212wi25.netlify.app/schedule)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: false\n    incremental: false \n    chalkboard: true\nhtml-math-method:\n  method: mathjax\n  url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\nexecute:\n  freeze: auto\n  echo: true\n  cache: false\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib  \n---\n\n\n\n\n\n## Application exercise\n\n::: appex\n📋 [AE 06 - Transformations + Outliers](/ae/ae-06-transformations.qmd)\n:::\n\nComplete Exercises 0 and 1.\n\n## Computational set up\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(broom)       # for formatting model output\nlibrary(ggformula)   # for creating plots using formulas\nlibrary(scales)      # for pretty axis labels\nlibrary(knitr)       # for pretty tables\nlibrary(moderndive)  # for house_price dataset\nlibrary(fivethirtyeight)   # for fandango dataset\nlibrary(kableExtra)  # also for pretty tables\nlibrary(patchwork)   # arrange plots\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))\n```\n:::\n\n\n\n## Data: `house_prices` {.smaller}\n\n::: nonincremental\n-   Contains house sale prices for King County, which includes Seattle, from homes\nsold between May 2014 and May 2015\n-   Obtained from [Kaggle.com](https://www.kaggle.com/harlfoxem/housesalesprediction/data)\n-   Imported from the `moderndive` package\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglimpse(house_prices)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 21,613\nColumns: 21\n$ id            <chr> \"7129300520\", \"6414100192\", \"5631500400\", \"2487200875\", …\n$ date          <date> 2014-10-13, 2014-12-09, 2015-02-25, 2014-12-09, 2015-02…\n$ price         <dbl> 221900, 538000, 180000, 604000, 510000, 1225000, 257500,…\n$ bedrooms      <int> 3, 3, 2, 4, 3, 4, 3, 3, 3, 3, 3, 2, 3, 3, 5, 4, 3, 4, 2,…\n$ bathrooms     <dbl> 1.00, 2.25, 1.00, 3.00, 2.00, 4.50, 2.25, 1.50, 1.00, 2.…\n$ sqft_living   <int> 1180, 2570, 770, 1960, 1680, 5420, 1715, 1060, 1780, 189…\n$ sqft_lot      <int> 5650, 7242, 10000, 5000, 8080, 101930, 6819, 9711, 7470,…\n$ floors        <dbl> 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1…\n$ waterfront    <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ view          <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0,…\n$ condition     <fct> 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 4, 4,…\n$ grade         <fct> 7, 7, 6, 7, 8, 11, 7, 7, 7, 7, 8, 7, 7, 7, 7, 9, 7, 7, 7…\n$ sqft_above    <int> 1180, 2170, 770, 1050, 1680, 3890, 1715, 1060, 1050, 189…\n$ sqft_basement <int> 0, 400, 0, 910, 0, 1530, 0, 0, 730, 0, 1700, 300, 0, 0, …\n$ yr_built      <int> 1955, 1951, 1933, 1965, 1987, 2001, 1995, 1963, 1960, 20…\n$ yr_renovated  <int> 0, 1991, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ zipcode       <fct> 98178, 98125, 98028, 98136, 98074, 98053, 98003, 98198, …\n$ lat           <dbl> 47.5112, 47.7210, 47.7379, 47.5208, 47.6168, 47.6561, 47…\n$ long          <dbl> -122.257, -122.319, -122.233, -122.393, -122.045, -122.0…\n$ sqft_living15 <int> 1340, 1690, 2720, 1360, 1800, 4760, 2238, 1650, 1780, 23…\n$ sqft_lot15    <int> 5650, 7639, 8062, 5000, 7503, 101930, 6819, 9711, 8113, …\n```\n\n\n:::\n:::\n\n\n\n## Variables\n\n- Outcome\n  + `price`: the sale price in dollars\n- Predictor \n  + `sqft_living`: the square footage of the home\n  \n## Recap: Fit the model\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhp_fit <- lm(price ~ sqft_living, data = house_prices)\ntidy(hp_fit) |>  kable(digits = 2)\n```\n\n::: {.cell-output-display}\n\n\n|term        |  estimate| std.error| statistic| p.value|\n|:-----------|---------:|---------:|---------:|-------:|\n|(Intercept) | -43580.74|   4402.69|     -9.90|       0|\n|sqft_living |    280.62|      1.94|    144.92|       0|\n\n\n:::\n:::\n\n\n\n:::{.incremental}\n- Write down the model:\n  + **Model:** $\\hat{\\text{price}} = -43580.74 + 280.62\\times\\text{sqft_living}$\n- Interpret the slope and intercept in the context of this problem:\n  + **Interpretation:** If the square footage of the house increases by 1, the price increases by and average of \\$280.62 and a (theoretical) house with 0 square feet with cost -\\$43,580.74.\n:::\n\n## Recap: Fit the model\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\ngf_point(price ~ sqft_living, data = house_prices,\n         alpha = 0.25, size = 0.01) |> \n  gf_smooth(method = \"lm\", color = \"red\") |> \n  gf_labs(x = \"Square Footage\", \n       y = \"Sale Price\")  |> \n  gf_refine(scale_y_continuous(labels = label_dollar()),\n  scale_x_continuous(labels = label_number()))\n```\n\n::: {.cell-output-display}\n![](06-slr-transformations_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## Recap: Model conditions\n\n1.  **Linearity:** There is a linear relationship between the outcome and predictor variables\n2.  **Constant variance:** The variability of the errors is equal for all values of the predictor variable\n3.  **Normality:** The errors follow a normal distribution\n4.  **Independence:** The errors are independent from each other\n\n. . .\n\n::: question\nHow should we check these assumptions?\n:::\n\n## Recap: Residual Histogram\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nhp_aug <- augment(hp_fit)\n\ngf_histogram(~.resid, data = hp_aug, bins = 100) |> \n  gf_labs(x = \"Residual\", \n       y = \"Count\", \n       title = \"Residual Histogram\")\n```\n\n::: {.cell-output-display}\n![](06-slr-transformations_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## Recap: QQ-Plot of Residuals\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\ngf_qq(~.resid, data = hp_aug) |> \n  gf_qqline() |>\n  gf_labs(x = \"Theoretical quantile\", \n       y = \"Observed quantile\", \n       title = \"Normal QQ-plot of residuals\")\n```\n\n::: {.cell-output-display}\n![](06-slr-transformations_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## Recap: Residuals vs. Fitted Values\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\ngf_point(.resid ~ .fitted, data = hp_aug, \n         alpha = 0.25, size = 0.01) |> \n  gf_hline(yintercept = 0, linetype = \"dashed\") |> \n  gf_labs(\n    x = \"Fitted value\", y = \"Residual\",\n    title = \"Residuals vs. fitted values\"\n  )\n```\n\n::: {.cell-output-display}\n![](06-slr-transformations_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n## [Are model conditions satisfied?]{.r-fit-text}\n\n1.  **Linearity:** ``❓``\n2.  **Constant variance:** ``❌``\n3.  **Normality:** ``❌``\n4.  **Independence:** ``✅``\n\n## [What to do when regression conditions are violated]{.r-fit-text}\n\nExamples:\n\n1. Lack of normality in residuals \n2. Patterns in residuals\n3. Heteroscedasticity (non-constant variance)\n4. Outliers: influential points, large residuals\n\n\n# Transformations\n\n## Data Transformations\n\nCan be used to:\n\na. Address nonlinear patterns\nb. Stabilize variance\nc. Remove skewness from residuals\nd. Minimize effects of outliers\n\n## Common Transformations\n\nFor either the response $Y$ or predictor $X$:\n\n- Logarithm $Z \\to \\log(Z)$\n  - Note: \"log\" means \"log base $e$\"\n- Square Root $Z \\to \\sqrt{Z}$\n- Exponential $Z \\to e^Z$\n- Power functions $Z \\to Z^2, Z^3, Z^4, \\ldots$\n- Reciprocal $Z \\to 1/Z$\n\n## General Approach\n\n- Fix non-constant variance be transforming $Y$ (do this first)\n    + Fan Pattern: Log-Transform $Y$\n- Fix non-linearity by transforming $X$\n\n\n## Why a Log Transformation? {.smaller}\n\n> Some relationship are *multiplicative* (not linear)\n\nExample: Area of a circle\n\n$$\n\\begin{aligned}\nA &= \\pi r^2 \\text{ (not linear)}\\\\\n\\log(A) &= \\log(\\pi r^2)\n= \\log(\\pi) + 2\\log(r)\\\\\n\\log(A) &= \\beta_0 + \\beta_1\\times \\log(r)\\\\\n\\implies & \\log(A) \\text{ is a linear function of } \\log(r)\n\\end{aligned}\n$$\n\nLook for:\n\n- Increasing variability in scatterplot\n- Strongly right-skewed residual distributions\n- Complete Exercise 2\n\n## Fixing non-linearity\n\n-   Many departures from linearity can be solved with power transformations (e.g. $X^{power}$)\n\n    +   For technical reasons, $power = 0$ corresponds to $\\log$\n\n-   Concave down pattern $\\Rightarrow$ transform down (i.e. $power < 1$)\n\n    +   $\\log$ is typically a good first choice\n\n-   Concave up pattern $\\Rightarrow$ transform up (i.e. $power > 1$)\n\n-   Complete Exercises 3-5.\n\n\n## Back to `house_sales`\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\np1 <- gf_point(price ~ sqft_living, data = house_prices,\n         alpha = 0.25, size = 0.01) |> \n  gf_smooth(method = \"lm\", color = \"red\") |> \n  gf_labs(x = \"Square Footage\", \n       y = \"Sale Price\")  |> \n  gf_refine(scale_y_continuous(labels = label_dollar()),\n  scale_x_continuous(labels = label_number()))\n\np2 <- gf_point(log(price) ~ sqft_living, data = house_prices,\n         alpha = 0.25, size = 0.01) |> \n  gf_smooth(method = \"lm\", color = \"red\") |> \n  gf_labs(x = \"Square Footage\", \n       y = \"log(Sale Price)\")  |> \n  gf_refine(scale_y_continuous(labels = label_dollar()),\n  scale_x_continuous(labels = label_number()))\n\np3 <- gf_point(price ~ log(sqft_living), data = house_prices,\n         alpha = 0.25, size = 0.01) |> \n  gf_smooth(method = \"lm\", color = \"red\") |> \n  gf_labs(x = \"log(Square Footage)\", \n       y = \"Sale Price\")  |> \n  gf_refine(scale_y_continuous(labels = label_dollar()),\n  scale_x_continuous(labels = label_number()))\n\np4 <- gf_point(log(price) ~ log(sqft_living), data = house_prices,\n         alpha = 0.25, size = 0.01) |> \n  gf_smooth(method = \"lm\", color = \"red\") |> \n  gf_labs(x = \"log(Square Footage)\", \n       y = \"log(Sale Price)\")  |> \n  gf_refine(scale_y_continuous(labels = label_dollar()),\n  scale_x_continuous(labels = label_number()))\n\n(p1 + p2)/ (p3 + p4)\n```\n\n::: {.cell-output-display}\n![](06-slr-transformations_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## Fitting Transformed Models {.smaller}\n\n::::{.columns}\n:::{.column}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlogprice_model <- lm(log(price) ~ sqft_living, data = house_prices)\ntidy(logprice_model) |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|term        |   estimate| std.error| statistic| p.value|\n|:-----------|----------:|---------:|---------:|-------:|\n|(Intercept) | 12.2184641| 0.0063741| 1916.8830|       0|\n|sqft_living |  0.0003987| 0.0000028|  142.2326|       0|\n\n\n:::\n:::\n\n\n\n$$\n\\begin{aligned}\n\\log(Y) &= 12.22  + 3.99\\times 10^{-4}\\times X\\\\\nY &= e^{12.22 + 3.99\\times 10^{-4}\\times X}\\\\\n&= 202805\\times e^{3.99\\times 10^{-4}\\times X}\n\\end{aligned}\n$$\n:::\n:::{.column}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nloglog_model <- lm(log(price) ~ log(sqft_living), data = house_prices)\ntidy(loglog_model) |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|term             | estimate| std.error| statistic| p.value|\n|:----------------|--------:|---------:|---------:|-------:|\n|(Intercept)      | 6.729916| 0.0470620|  143.0011|       0|\n|log(sqft_living) | 0.836771| 0.0062233|  134.4587|       0|\n\n\n:::\n:::\n\n\n$$\n\\begin{aligned}\n\\log(Y) &=6.73 + 0.837\\times \\log(X)\\\\\n\\log(Y) &= \\log(e^{6.73})  + \\log(X^{0.837})\\\\\nY &= 873.15\\times X^{0.837}\n\\end{aligned}\n$$\n:::\n::::\n\n## Residuals Histograms\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nlp_aug <- augment(logprice_model)\nll_aug <- augment(loglog_model)\n\np1 <- gf_histogram(~.resid, data = lp_aug, bins = 100) |> \n  gf_labs(x = \"Residual\", \n       y = \"Count\", \n       title = \"Log Price Residuals\")\n\np2 <- gf_histogram(~.resid, data = ll_aug, bins = 100) |> \n  gf_labs(x = \"Residual\", \n       y = \"Count\", \n       title = \"Log-Log Residuals\")\n\n(p1 + p2)\n```\n\n::: {.cell-output-display}\n![](06-slr-transformations_files/figure-revealjs/unnamed-chunk-10-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## QQ-Plots of Residuals\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\np1 <- gf_qq(~.resid, data = lp_aug) |> \n  gf_qqline() |>\n  gf_labs(x = \"Theoretical quantile\", \n       y = \"Observed quantile\", \n       title = \"Log Price QQ\")\n\np2 <- gf_qq(~.resid, data = ll_aug) |> \n  gf_qqline() |>\n  gf_labs(x = \"Theoretical quantile\", \n       y = \"Observed quantile\", \n       title = \"Log-Log QQ\")\n\np1 + p2\n```\n\n::: {.cell-output-display}\n![](06-slr-transformations_files/figure-revealjs/unnamed-chunk-11-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## Residuals vs. Fitted Values\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\np1 <- gf_point(.resid ~ .fitted, data = lp_aug, \n         alpha = 0.25, size = 0.01) |> \n  gf_hline(yintercept = 0, linetype = \"dashed\") |> \n  gf_labs(\n    x = \"Fitted value\", y = \"Residual\",\n    title = \"Log Price Model\"\n  )\n\np2 <- gf_point(.resid ~ .fitted, data = ll_aug, \n         alpha = 0.25, size = 0.01) |> \n  gf_hline(yintercept = 0, linetype = \"dashed\") |> \n  gf_labs(\n    x = \"Fitted value\", y = \"Residual\",\n    title = \"Log-Log Model\"\n  )\n\np1 + p2\n```\n\n::: {.cell-output-display}\n![](06-slr-transformations_files/figure-revealjs/unnamed-chunk-12-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## A note on evaluation\n\nIf you are computing your evaluation metrics (e.g. $R^2$ or RMSE), you should transform your predictions BACK to their original scale, especially if you're trying to choose the best model\n\n:::{.question}\n- Why do we need to undo the transformation for evaluation metrics by not residuals plots? \n- Why don't we need to worry about the predictors?\n:::\n\n# Outliers\n\n## Types of \"Unusual\" Points in SLR\n\n- **Outlier**: a data point that is far from the regression line\n- **Influential point**: a data point that has a large effect on the regression fit\n\n. . .\n\n:::{.question}\n- How do we measure \"far\"?\n- How do we measure \"effect on the fit\"?\n:::\n\n## Detecting Unusual Cases: Overview\n\n1. Compute residuals\n    + \"raw\", standardized, studentized\n2. Plots of residuals\n    + boxplot, scatterplot, normal plot\n3. Leverage\n    + unusual values for the predictors\n  \n## Example: Movie scores\n\n::: columns\n::: {.column width=\"70%\"}\n-   Data behind the FiveThirtyEight story [*Be Suspicious Of Online Movie Ratings*](https://fivethirtyeight.com/features/fandango-movies-ratings/)[*, Especially Fandango's*](%22Be%20Suspicious%20Of%20Online%20Movie%20Ratings,%20Especially%20Fandango's%22)\n-   In the **fivethirtyeight** package: [`fandango`](https://fivethirtyeight-r.netlify.app/reference/fandango.html)\n-   Contains every film released in 2014 and 2015 that has at least 30 fan reviews on Fandango, an IMDb score, Rotten Tomatoes critic and user ratings, and Metacritic critic and user scores\n:::\n\n::: {.column width=\"30%\"}\n![](images/06/fandango.png){fig-alt=\"Fandango logo\" width=\"200\"}\n\n![](images/06/imdb.png){fig-alt=\"IMDB logo\" width=\"200\"}\n\n![](images/06/rotten-tomatoes.png){fig-alt=\"Rotten Tomatoes logo\" width=\"200\"}\n\n![](images/06/metacritic.png){fig-alt=\"Metacritic logo\" width=\"200\"}\n:::\n:::\n\n## Data prep\n\n-   Rename Rotten Tomatoes columns as `critics` and `audience`\n-   Rename the dataset as `movie_scores`\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata(\"fandango\")\n\nmovie_scores <- fandango |>\n  rename(critics = rottentomatoes, \n         audience = rottentomatoes_user)\n```\n:::\n\n\n\n## Example: Movie Scores\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nmovie_scores |> \n  gf_point(audience ~ critics) |> \n  gf_lm() |> \n  gf_labs(x = \"Critics Score\", \n       y = \"Audience Score\")\n```\n\n::: {.cell-output-display}\n![](06-slr-transformations_files/figure-revealjs/unnamed-chunk-13-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## Boxplot of Residuals\n\n:::{.smaller}\n\n\n::: {.cell layout-align=\"center\" output-location='column'}\n\n```{.r .cell-code}\nmovie_fit <- lm(audience ~ critics, data = movie_scores)\nmovie_fit_aug <- augment(movie_fit)\n\ngf_boxplot(.resid ~ \"\", data = movie_fit_aug, \n           fill = \"salmon\", ylab = \"Residuals\", xlab = \"\")\n```\n\n::: {.cell-output-display}\n![](06-slr-transformations_files/figure-revealjs/unnamed-chunk-14-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n:::\n\n- Dots (outliers) indicate data points more than 1.5 IQRs above (or below) quartiles\n\n## Standardized Residuals\n\n:::{.incremental}\n- Recall: Z-scores\n- Fact: If $X$ has mean $\\mu$ and standard deviation $\\sigma$, then $(X-\\mu)/\\sigma$ has mean 0 and standard deviation 1\n- For residuals: mean 0 and standard deviation $\\hat{\\sigma}_\\epsilon$\n- **Standardized residuals:** $\\frac{y_i-\\hat{y}_i}{\\hat{\\sigma}_\\epsilon}$\n  + Look for values beyond $\\pm 2$ or $\\pm 3$\n:::\n\n## Recap: `Augment` function\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmovie_fit_aug |> \n  head() |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n| audience| critics|  .fitted|     .resid|      .hat|   .sigma|   .cooksd| .std.resid|\n|--------:|-------:|--------:|----------:|---------:|--------:|---------:|----------:|\n|       86|      74| 70.69768|  15.302321| 0.0081597| 12.51615| 0.0061774|  1.2254688|\n|       80|      85| 76.40313|   3.596866| 0.0112688| 12.57830| 0.0004743|  0.2885034|\n|       90|      80| 73.80975|  16.190255| 0.0096283| 12.50817| 0.0081839|  1.2975389|\n|       84|      18| 41.65173|  42.348272| 0.0207618| 12.06226| 0.1234982|  3.4131653|\n|       28|      14| 39.57702| -11.577018| 0.0234805| 12.54373| 0.0104964| -0.9343768|\n|       62|      63| 64.99222|  -2.992225| 0.0068844| 12.57943| 0.0001988| -0.2394750|\n\n\n:::\n:::\n\n\n\n## Example: Movie Scores\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\np1 <- movie_fit_aug |>  # Augmented data\n  gf_boxplot(\"\" ~ .std.resid, \n           xlab = \"Standardized Residual\")\n\np2 <- movie_fit_aug |>  # Augmented data\n  gf_point(.std.resid ~ .fitted, \n           xlab = \"Predicted\", ylab = \"Standardized Residual\")\n\np1 + p2\n```\n\n::: {.cell-output-display}\n![](06-slr-transformations_files/figure-revealjs/unnamed-chunk-16-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## (Externally) Studentized Residuals\n\n- Concern: An unusual value may exert great influence on the fit\n  + Its residual might be underestimated because the model \"moves\" a lot to fit it\n  + The standard error may also be inflated due to the outlier error\n- **Studentize:** Fit the model *without* that case, then find new $\\hat{\\sigma}_\\epsilon$\n\n## Example: Movie Scores\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmovie_fit_aug |>  # Augmented data\n  mutate(studentized_residual = rstudent(movie_fit)) |> \n  gf_point(studentized_residual ~ .fitted, \n           xlab = \"Predicted\", ylab = \"Studentized Residual\")\n```\n\n::: {.cell-output-display}\n![](06-slr-transformations_files/figure-revealjs/unnamed-chunk-17-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## What to do with an outlier?\n\n- Look into it\n- If something is unusual about it and you can make a case that it is not a good representation of the population you can throw it out\n- If not and the value is just unusual, keep it\n\n## Influence vs. Leverage\n\n- **High Influence Point**: point that DOES impact the regression line\n- **High Leverage Point**: point with \"potential\" to impact regression line because $X$-value is unusual\n\n## High Leverage, Low Influence\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-slr-transformations_files/figure-revealjs/unnamed-chunk-18-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## High Leverage, High Influence\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-slr-transformations_files/figure-revealjs/unnamed-chunk-19-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## Low Leverage, Low Influence\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-slr-transformations_files/figure-revealjs/unnamed-chunk-20-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n\n## Low Leverage, High Influence\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-slr-transformations_files/figure-revealjs/unnamed-chunk-21-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## Low Leverage, High Influence\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-slr-transformations_files/figure-revealjs/unnamed-chunk-22-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n\n## Recap {.smaller}\n\n- Transformations\n  + Transform $Y$ to fix non-constant variance (and non-normality)\n  + Transform $X$ to fix non-linearity\n  + Power transformations are powerful (concave up/drown $\\Rightarrow$ power up/down)\n  + logs allow us to model a lot of non-linear relationships with a linear model\n- Outliers\n  + Leverage\n  + Influence\n  + Used plots of residuals, standardized residuals, and studentized residuals to diagnose outliers\n- Spend the rest of class working on Exercise 6.",
    "supporting": [
      "06-slr-transformations_files\\figure-revealjs"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}