{
  "hash": "cecf7f9b7af3ab5aa22c14e1bad7dca5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Logistic regression\"\nsubtitle: \"Introduction\"\nauthor: \"Prof. Eric Friedlander\"\nfooter: \"[ðŸ”— MAT 212 - Winter 2025 -  Schedule](https://mat212wi25.netlify.app/schedule)\"\nlogo: \"../images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: false\n    transition: fade\n    slide-number: false\n    incremental: false \n    chalkboard: true\nhtml-math-method:\n  method: mathjax\n  url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\nexecute:\n  freeze: auto\n  echo: true\n  cache: false\nknitr:\n  opts_chunk: \n    R.options:      \n    width: 200\nbibliography: references.bib  \n---\n\n\n\n\n\n## Application Exercise\n\n::: appex\nðŸ“‹ [AE 09 - Intro to Logistic Regression](/ae/ae-09-logistic-intro.qmd)\n\n- Complete Exercises 0-2.\n:::\n\n\n# Logistic regression\n\n## Topics\n\n-   Introduction to modeling categorical data\n\n-   Logistic regression for *binary* response variable\n\n-   Relationship between odds and probabilities\n\n## Computational setup\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)\nlibrary(ggformula)\nlibrary(broom)\nlibrary(knitr)\nlibrary(ggforce)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_bw(base_size = 20))\n```\n:::\n\n\n\n# Predicting categorical outcomes\n\n## Types of outcome variables\n\n**Quantitative outcome variable**:\n\n-   Sales price of a house\n-   **Model**: Expected sales price given the number of bedrooms, lot size, etc.\n\n. . .\n\n**Categorical outcome variable**:\n\n-   Indicator for developing coronary heart disease in the next 10 years\n-   **Model**: Probability an adult is high risk of heart disease in the next 10 years given their age, total cholesterol, etc.\n\n## Models for categorical outcomes\n\n::: columns\n::: {.column width=\"50%\"}\n**Logistic regression**\n\n2 Outcomes\n\n- 1: \"Success\" (models probability of this category...)\n- 0: \"Failure\"\n:::\n\n::: {.column width=\"50%\"}\n**Multinomial logistic regression**\n\n3+ Outcomes\n\n- 1: Democrat\n- 2: Republican\n- 3: Independent\n:::\n:::\n\n## 2024 election forecasts\n\n[The Economist](https://www.economist.com/interactive/us-2024-election/prediction-model/president)\n\n\n## 2020 NBA finals predictions\n\n![](images/19/nba-predictions.png){fig-align=\"center\"}\n\nSource: [FiveThirtyEight 2019-20 NBA Predictions](https://projects.fivethirtyeight.com/2020-nba-predictions/games/?ex_cid=rrpromo)\n\n## Data: Framingham Study {.smaller}\n\nThis data set is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. We want to use the patients age to predict if a randomly selected adult is high risk for heart disease in the next 10 years.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nheart_disease <- read_csv(\"../data/framingham.csv\") |>\n  select(totChol, TenYearCHD, age, BMI, cigsPerDay, heartRate) |>\n  drop_na()\n```\n:::\n\n\n\n## Variables\n\n- Response: \n    -   `TenYearCHD`:\n        -   1: Patient developed heart disease within 10 years of exam\n        -   0: Patient did not develop heart disease within 10 years of exam\n- Predictor: \n  -   `age`: age in years at time of visit    \n\n\n## Plot the data\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-logistic-intro_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n## Let's fit a linear regression model\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-logistic-intro_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\nðŸ›‘ *This model produces predictions outside of 0 and 1.*\n\n## Let's try another model\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-logistic-intro_files/figure-revealjs/logistic-model-plot-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n## Let's try another model: Zooming Out\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-logistic-intro_files/figure-revealjs/logistic-model-plot-2-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n*âœ… This model (called a **logistic regression model**) only produces predictions between 0 and 1.*\n\n## The code\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nheart_disease |> \n  gf_point(TenYearCHD ~ age)  |>\n  gf_hline(yintercept = c(0,1), lty = 2) |> \n  gf_labs(y = \"CHD Risk\", x = \"Age\") |> \n  gf_refine(stat_smooth(method =\"glm\", method.args = list(family = \"binomial\"), \n              fullrange = TRUE, se = FALSE))\n```\n:::\n\n\n\n## Different types of models\n\n| Method                          | Outcome      | Model                                                     |\n|---------------------------------|--------------|-----------------------------------------------------------|\n| Linear regression               | Quantitative | $Y = \\beta_0 + \\beta_1~ X$                                |\n| Linear regression (transform Y) | Quantitative | $\\log(Y) = \\beta_0 + \\beta_1~ X$                          |\n| Logistic regression             | Binary       | $\\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1 ~ X$ |\n\n**Note:** In this class (and in most college level math classes) ((and and in R))  $\\log$ means log base $e$ (i.e. natural log)\n\n## Linear vs. logistic regression\n\nComplete Exercise 3.\n\n## Linear vs. logistic regression\n\n::: question\nState whether a linear regression model or logistic regression model is more appropriate for each scenario.\n\n1.  Use age and education to predict if a randomly selected person will vote in the next election.\n\n2.  Use budget and run time (in minutes) to predict a movie's total revenue.\n\n3.  Use age and sex to calculate the probability a randomly selected adult will visit St. Lukes in the next year.\n:::\n\n# Odds and probabilities\n\n## Binary response variable\n\n::: incremental\n-   $Y$: \n    +   1: \"success\" (not necessarily a good thing)\n    +   0: \"failure\"\n-   $\\pi$: **probability** that $Y=1$, i.e., $P(Y = 1)$\n-   $\\frac{\\pi}{1-\\pi}$: **odds** that $Y = 1$\n-   $\\log\\big(\\frac{\\pi}{1-\\pi}\\big)$: **log-odds**\n-   Go from $\\pi$ to $\\log\\big(\\frac{\\pi}{1-\\pi}\\big)$ using the **logit transformation**\n:::\n\n## Odds {.smaller}\n\n::: incremental\nSuppose there is a **70% chance** it will rain tomorrow\n\n-   Probability it will rain is $\\mathbf{p = 0.7}$\n-   Probability it won't rain is $\\mathbf{1 - p = 0.3}$\n-   Odds it will rain are **7 to 3**, **7:3**, $\\mathbf{\\frac{0.7}{0.3} \\approx 2.33}$\n    +   For every 3 times it doesn't rain, it will rain 7 times\n    +   For every time it *doesn't* rain, it will rain 2.33 times\n-   Log-Odds it will rain is $\\log\\mathbf{\\frac{0.7}{0.3} \\approx \\log(2.33) \\approx 0.847}$\n    +   Negative $\\Rightarrow$ probability of success less than 50-50 (0.5)\n    +   Positive $\\Rightarrow$ probability of success greater than 50-50 (0.5)\n    +   What are the log-odds of of a probability of 0? What about 1?\n:::\n\n\n## From log-odds to probabilities\n\n::: columns\n::: {.column width=\"50%\"}\n**log-odds**\n\n$$\\omega = \\log \\frac{\\pi}{1-\\pi}$$\n\n**odds**\n\n$$e^\\omega = \\frac{\\pi}{1-\\pi}$$\n:::\n\n::: {.column width=\"50%\"}\n**probability**\n\n$$\\pi = \\frac{e^\\omega}{1 + e^\\omega}$$\n:::\n:::\n\nComplete Exercise 4-5.\n\n# Logistic regression\n\n## From odds to probabilities {.incremental}\n\n(1) **Logistic model**: log-odds = $\\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1~X$\n(2) **Odds =** $\\exp\\big\\{\\log\\big(\\frac{\\pi}{1-\\pi}\\big)\\big\\} = \\frac{\\pi}{1-\\pi}$\n(3) Combining (1) and (2) with what we saw earlier\n\n. . .\n\n$$\\text{probability} = \\pi = \\frac{\\exp\\{\\beta_0 + \\beta_1~X\\}}{1 + \\exp\\{\\beta_0 + \\beta_1~X\\}}$$\n\n## Logistic regression model\n\n**Logit form**: $$\\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1~X$$\n\n. . .\n\n**Probability form**:\n\n$$\n\\pi = \\frac{\\exp\\{\\beta_0 + \\beta_1~X\\}}{1 + \\exp\\{\\beta_0 + \\beta_1~X\\}}\n$$\n\n## Variables\n\n- Response: \n    -   `TenYearCHD`:\n        -   1: Patient developed heart disease within 10 years of exam\n        -   0: Patient did not develop heart disease within 10 years of exam\n- Predictors: \n  -   `age`: age in years\n\n\n# Logistic regression\n\n## Logistic regression model\n\n**Logit form**: $$\\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1~X$$\n\n. . .\n\n**Probability form**:\n\n$$\n\\pi = \\frac{\\exp\\{\\beta_0 + \\beta_1~X\\}}{1 + \\exp\\{\\beta_0 + \\beta_1~X\\}}\n$$\n\n. . .\n\nToday: Using R to fit this model.\n\n\n\n## TenYearCHD vs. age\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nheart_disease |> \ngf_sina(age ~ factor(TenYearCHD)) |> \n  gf_labs(x = \"TenYearCHD - 1: yes, 0: no\",\n       y = \"Age\", \n       title = \"Age vs. Ten YearCHD\")\n```\n\n::: {.cell-output-display}\n![](09-logistic-intro_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n## TenYearCHD vs. age\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nheart_disease |> \ngf_violin(age ~ factor(TenYearCHD), fill = \"steelblue\") |> \n  gf_labs(x = \"TenYearCHD - 1: yes, 0: no\",\n       y = \"Age\", \n       title = \"Age vs. TenYearCHD\")\n```\n\n::: {.cell-output-display}\n![](09-logistic-intro_files/figure-revealjs/unnamed-chunk-10-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n## TenYearCHD vs. age\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nheart_disease |> \ngf_boxplot(age ~ factor(TenYearCHD), fill = \"steelblue\") |> \n  gf_sina(size = 0.75, alpha=0.25) |> \n  gf_labs(x = \"TenYearCHD - 1: yes, 0: no\",\n       y = \"Age\", \n       title = \"Age vs. TenYearCHD\")\n```\n\n::: {.cell-output-display}\n![](09-logistic-intro_files/figure-revealjs/unnamed-chunk-11-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n## Let's fit a model\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"1|3\"}\nheart_disease_fit <- glm(TenYearCHD ~ age, data = heart_disease, family = \"binomial\")\n\ntidy(heart_disease_fit) |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|term        |   estimate| std.error| statistic| p.value|\n|:-----------|----------:|---------:|---------:|-------:|\n|(Intercept) | -5.6614125| 0.2899446| -19.52584|       0|\n|age         |  0.0763254| 0.0053760|  14.19754|       0|\n\n\n:::\n:::\n\n\n\n## The model {.smaller}\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(heart_disease_fit) |> kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value|\n|:-----------|--------:|---------:|---------:|-------:|\n|(Intercept) |   -5.661|     0.290|   -19.526|       0|\n|age         |    0.076|     0.005|    14.198|       0|\n\n\n:::\n:::\n\n\n\n\n$$\\textbf{Logit form:}\\qquad\\log\\Big(\\frac{\\hat{\\pi}}{1-\\hat{\\pi}}\\Big) = -5.561 + 0.076 \\times \\text{age}$$ \n\n$$\\textbf{Probability form:}\\qquad\\hat{\\pi} = \\frac{\\exp(-5.561 + 0.076 \\times \\text{age})}{1+\\exp(-5.561 + 0.075 \\times \\text{age})}$$\n\nwhere $\\hat{\\pi}$ is the predicted probability of developing heart disease in the next 10 years.\n\n## Interpreting $\\hat{\\beta}$'s\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(heart_disease_fit) |> kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value|\n|:-----------|--------:|---------:|---------:|-------:|\n|(Intercept) |   -5.661|     0.290|   -19.526|       0|\n|age         |    0.076|     0.005|    14.198|       0|\n\n\n:::\n:::\n\n\n\nFor every addition year of age, the **log-odds** of developing heart disease in the next 10 years, increases by 0.076.\n\n. . .\n\n\nComplete Exercises 6-8.\n\n## Interpretability of $\\beta$ for predicted probabilities\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](09-logistic-intro_files/figure-revealjs/unnamed-chunk-15-1.png){fig-align='center' width=90%}\n:::\n:::\n\n\n\n-   SLOPE IS CHANGING!\n-   Increase in $\\hat{\\pi}$ due to increase of 1 year of Age *depends on what starting age is*\n\n## `glm` and `augment` {.smaller}\n\nThe `.fitted` values in `augment` correspond to predictions from the logistic form of the model (i.e. the log-odds):\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\naugment(heart_disease_fit)  |> head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 Ã— 8\n  TenYearCHD   age .fitted .resid     .hat .sigma   .cooksd .std.resid\n       <dbl> <dbl>   <dbl>  <dbl>    <dbl>  <dbl>     <dbl>      <dbl>\n1          0    39   -2.68 -0.363 0.000472  0.891 0.0000161     -0.363\n2          0    46   -2.15 -0.469 0.000330  0.891 0.0000192     -0.469\n3          0    48   -2.00 -0.504 0.000295  0.891 0.0000200     -0.504\n4          1    61   -1.01  1.62  0.000730  0.891 0.000999       1.62 \n5          0    46   -2.15 -0.469 0.000330  0.891 0.0000192     -0.469\n6          0    43   -2.38 -0.421 0.000393  0.891 0.0000182     -0.421\n```\n\n\n:::\n:::\n\n\n\n. . .\n\nNote: The residuals do not make sense here!\n\n**For observation 1**\n\n$$\\text{predicted probability} = \\hat{\\pi} = \\frac{\\exp\\{-2.680\\}}{1 + \\exp\\{-2.680\\}} = 0.0733$$\n\n## Using `predict` with `glm`\n\nDefault output is log-odds:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredict(heart_disease_fit, new_data = heart_disease) |> head() |> kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|      x|\n|------:|\n| -2.685|\n| -2.150|\n| -1.998|\n| -1.006|\n| -2.150|\n| -2.379|\n\n\n:::\n:::\n\n\n\n## Using `predict` with `glm`\n\nMore commonly you want the predicted probability:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredict(heart_disease_fit, newdata = heart_disease, type = \"response\") |> head() |> kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|     x|\n|-----:|\n| 0.064|\n| 0.104|\n| 0.119|\n| 0.268|\n| 0.104|\n| 0.085|\n\n\n:::\n:::\n\n\n\n. . .\n\nComplete Exercise 9\n\n\n## Recap\n\n-   Introduced logistic regression for binary response variable\n-   Described relationship between odds and probabilities\n-   Fit logistic regression models using `glm`\n-   Interpreted coefficients in logistic regression models\n-   Used logistic regression model to calculate predicted odds and probabilities\n-   Use `predict` to make predictions using `glm`\n",
    "supporting": [
      "09-logistic-intro_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}