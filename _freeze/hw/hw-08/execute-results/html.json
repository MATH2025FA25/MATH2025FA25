{
  "hash": "e00d12def147a83ca6b0def1f7602688",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"HW 08: Lego Prices\" \neditor: visual\nformat:\n  html:\n    embed-resources: true\n---\n\n\n\n# Introduction\n\nIn this homework you will use multiple linear regression to fit and evaluate models using characteristics of LEGO sets to understand variability in the price.\n\n## Learning goals\n\nIn this assignment, you will...\n\n-   Use exploratory data analysis to inform feature engineering steps\n-   Evaluate and compare models\n-   Assess model conditions\n-   Use inference to draw conclusions\n\n## Getting started\n\n-   Go to [RStudio](https://rstudio.collegeofidaho.edu) and login with your College of Idaho Email and Password.\n\n-   Make a subfolder in your `hw` directory to store this homework.\n\n-   Log into [Canvas](https://cofi.instructure.com/courses/17093/assignments/202866), navigate to Homework 8 and upload the `hw-08.qmd` and `lego-sample.csv` files into the folder your just made.\n\n## Packages\n\nThe following packages will be used in this assignment:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(ggformula)\nlibrary(knitr) \nlibrary(rms)\nlibrary(patchwork)\n# add other packages as needed\n```\n:::\n\n\n\n::: callout-important\nAll narrative should be written in complete sentences, and all visualizations should have informative titles and axis labels.\n:::\n\n## Data: LEGOs\n\nThe data for this analysis includes information about LEGO sets from themes produced January 1, 2018 and September 11, 2020. The data were originally scraped from Brickset.com, an online LEGO set guide and were obtained for this assignment from Peterson and Ziegla ([2021](https://www.tandfonline.com/doi/full/10.1080/26939169.2021.1946450)).\n\nYou will work with data on about 400 randomly selected LEGO sets produced during this time period. The primary variables are interest in this analysis are\n\n-   `Pieces`: Number of pieces in the set from brickset.com.\n-   `Minifigures`: Number of minifigures (LEGO people) in the set scraped from brickset.com. LEGO sets with no minifigures have been coded as NA. NA's also represent missing data. This is due to how brickset.com reports their data.\n-   `Amazon_Price`: Amazon price of the set scraped from brickset.com (in U.S. dollars)\n-   `Size`: General size of the interlocking bricks (Large = LEGO Duplo sets - which include large brick pieces safe for children ages 1 to 5, Small = LEGO sets which- include the traditional smaller brick pieces created for age groups 5 and - older, e.g., City, Friends)\n-   `Theme`: Theme of the LEGO set\n-   `Year` : Year the LEGO set was produced\n-   `Pages`: Number of pages in the instruction booklet\n\n# Exercises\n\n::: callout-important\nAll narrative should be written in complete sentences, and all visualizations should have informative titles and axis labels.\n:::\n\n## Exercise 1\n\nThe data are contained in `lego-sample.csv`. Use the code below to read in the data, replace the `NA`s in `Minifigure` with 0, and remove any observations that have missing values for the relevant variables.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlegos <- read_csv(\"../data/lego-sample.csv\") |>\n  select(Size, Pieces, Theme, Amazon_Price, Year, Pages, Minifigures) |>\n  mutate(Minifigures = replace_na(Minifigures, 0)) |>\n  drop_na()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 400 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): Set_Name, Theme, Ages, Packaging, Weight, Availability, Size\ndbl (8): Item_Number, Pieces, Price, Amazon_Price, Year, Pages, Minifigures,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n\nLet's think about the analysis decisions we just made. We decided to drop all observations that have missing values for any of the relevant variables we identified. What are these advantages and disadvantages of doing this? Feel free to Google \"structurally missing data\". We also replaced ALL of the `NA`s in `Minifigures` with 0's. What are the advantages and disadvantages of doing this? Make sure you read the description of `Minifigures` in the introduction before answering.\n\n## Exercise 2\n\nVisualize the distributions of the predictor variables `Pieces`, `Size`, `Year`, and `Pages`. Neatly arrange the plots using the [patchwork](https://patchwork.data-imaginist.com/index.html) package. Create univariate visualizations not bivariate visualizations.\n\n## Exercise 3\n\nThe distribution of `Theme` is shown below. The bars are ordered by the frequency they occur in the data set.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlegos |>\n  count(Theme) |>\n  mutate(Theme = fct_reorder(Theme, n)) |> \ngf_col(Theme ~ n) |> \n    gf_labs(title = \"Lego Set Theme\", \n         y = \"Theme\", \n         x = \"Number of LEGO sets\")\n```\n\n::: {.cell-output-display}\n![](hw-08_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\nBased solely on information that is visible in this plot, what is one reason we should avoid putting the variable `Theme` in a model as is?\n\n## Exercise 4\n\nCreate a new variable called `Theme_coarse` that collapses any levels of `Theme` with fewer than 20 observations into a single category called `Other`. Hint: Look into the function `fct_lump_min`. You'll want to use it inside a `mutate` statement.\n\n## Exercise 5\n\nFit a model that uses the variables `Size`, `Theme_coarse`, and `Pages` to predict `Amazon_Price`. Call this `model1`.\n\n## Exercise 6\n\nCreate a new variable called `since2018` that calculates the number of years since 2018 based on the variable `Year`.\n\n## Exercise 7\n\nNow let's consider a new model that includes all the variables used in the model from Exercise 5 along with `since2018`, `Pieces`, and `Minifigures`. Call this `model2`\n\n## Exercise 8\n\nCompute the $R^2$, $R^2_{adj}$, AIC, and BIC for `model1` and `model2`. Based on your results, what model do you believe is the \"best\" model? Justify your answer citing specific evidence from the values you just generated. Note, they may not all be useful.\n\n## Exercise 9\n\nFor whichever model you chose above, determine whether the conditions for inference are met.\n\n## Exercise 10\n\nFor the same model, conduct an F-test and interpret your results in the context of the problem. Make sure to:\n\n1.  Identify the null and alternative hypotheses.\n2.  Compute the F-statistic.\n3.  Compute the p-value.\n4.  Interpret the result of your test at a significance level of $\\alpha = 0.05$\n\n# Grading (18 points)\n\n| Component             | Points |\n|-----------------------|--------|\n| Ex 1                  | 2      |\n| Ex 2                  | 1      |\n| Ex 3                  | 1      |\n| Ex 4                  | 1      |\n| Ex 5                  | 1      |\n| Ex 6                  | 1      |\n| Ex 7                  | 1      |\n| Ex 8                  | 4      |\n| Ex 9                  | 2      |\n| Ex 10                 | 2      |\n| Grammar & Writing     | 1[^1]  |\n| Workflow & formatting | 1[^2]  |\n\n[^1]: The \"Grammar & Writing\" grade is decided based on your grammar and writing. This is typically decided by choosing one of the questions and assessing the writing.\n\n[^2]: The \"Workflow & formatting\" grade is to assess the reproducible workflow and document format. This includes having a neatly organized document with readable code and your name and the date in the YAML.\n",
    "supporting": [
      "hw-08_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}